
((digest . "818a6bed982b8570e0e407a0268b7b42") (undo-list nil ("Explanation:
" . 15876) ((marker . 15876) . -13) ((marker . 11786) . -13) ((marker . 11786) . -13) ((marker) . -13) nil ("SQL> GRANT CREATE SESSION TO Sidney;
Grant succeeded.
SQL> conn sidney/out_standing1
Connected.
SQL> create table x(y number);
create table x(y number)
*
ERROR at line 1:
ORA-01031: insufficient privileges
SQL> conn / as sysdba
Connected.
SQL> grant resource to sidney;
Grant succeeded.
SQL> conn / as sysdba
Connected.
SQL> create table x(y number);
Table created.
SQL> insert into x values (3);
1 row created.
SQL> insert into x values (1);
1 row created.
SQL> insert into x values (5);
" . 13516) ((marker . 12497) . -152) ((marker . 12497) . -152) ((marker . 11626) . -96) ((marker . 11626) . -96) ((marker . 12252) . -351) ((marker . 12252) . -351) ((marker . 11360) . -458) ((marker . 11360) . -458) ((marker . 12255) . -228) ((marker . 12255) . -228) ((marker . 12342) . -206) ((marker . 12342) . -206) ((marker . 11698) . -85) ((marker . 11698) . -85) ((marker . 12494) . -154) ((marker . 12494) . -154) ((marker . 12141) . -320) ((marker . 12141) . -320) ((marker . 11433) . -489) ((marker . 11433) . -489) ((marker . 13502) . -458) ((marker . 11701) . -54) ((marker . 11701) . -54) ((marker . 12121) . -37) ((marker . 12121) . -37) ((marker . 12345) . -171) ((marker . 12345) . -171) ((marker . 12010) . -366) ((marker . 12010) . -366) ((marker . 11874) . -397) ((marker . 11874) . -397) ((marker . 11871) . -412) ((marker . 11871) . -412) ((marker . 11789) . -443) ((marker . 11789) . -443) ((marker . 12168) . -309) ((marker . 12168) . -309) ((marker . 12184) . -287) ((marker . 12184) . -287) ((marker . 12221) . -270) ((marker . 12221) . -270) ((marker . 11786) . -239) ((marker . 11786) . -239) ((marker . 11623) . -127) ((marker . 11623) . -127) ((marker) . -489) nil ("ｂ" . -4229) (4229 . 4230) (t 22854 4924 0 0) nil ("NEW QUESTION 192
……
P.S. These New 1Z0-062 Exam Questions Were Just Updated From The Real 1Z0-062 Exam, You Can Get The Newest 1Z0-062 Dumps In PDF And VCE From — http://bit.ly/1z0-062-dumps-vce-pdf (210q)
Good Luck !!!
New 1Z0-062 Exam Questions and Answers Updated Recently (21/Feb/2017):" . 94352) ((marker . 15876) . -290) ((marker . 93850) . -19) ((marker) . -290) nil ("
" . -89620) ((marker . 15876) . -1) ((marker) . -1) ((marker . 89118) . -1) ((marker . 89118) . -1) ((marker . 89118) . -1) nil ("
" . -89621) ((marker . 15876) . -1) ((marker) . -1) ((marker . 89118) . -1) ((marker . 89118) . -1) ((marker . 89118) . -1) nil ("




アップグレード前情報ツールについて言えば、3つのステートメントは正しいですか？
A.データベース内のすべてのユーザーのごみ箱をクリアし、ストレージスペースを解放します。
B.無効なSYSおよびSYSTEMオブジェクトのリストをレジストリ$ sys_inv_objsテーブルに書き込みます。
C.ネットワークユーティリティパッケージの依存関係を評価します。
D.使用されていないパラメータとサポートされていないパラメータを識別します。
E.修正スクリプトを生成し、自動的に実行して、ソースデータベースにフラグが立てられた問題を解決します。
回答：BCD
新しい質問182
どのアクティビティがデフォルトで監査され、データベース監査が有効かどうかに関係なく、オペレーティングシステムの監査証跡に記録されますか？
A.統一監査モードの構成
B. SYSDBA権限で接続されたユーザーによるSQLステートメントの実行
C. AUDIT声明の使用
D.きめ細かな監査ポリシーの作成
答え：B
新" . 89622) ((marker . 15876) . -447) ((marker) . -447) ((marker . 89118) . -447) ((marker . 89118) . -447) ((marker . 89118) . -447) ((marker) . -447) nil ("しい質問183
Oracle Database 12cへのアップグレード・プロセスを開始する前に、どの2つのタスクを実行する必要がありますか？
A.すべての読み取り専用表領域を読み取り書き込みモードにする
B.すべての無効なオブジェクトを再コンパイルする
C.互換性のあるパラメータを12 1 0 1に設定します。
D.辞書の統計情報を収集する
E.すべてのユーザーのごみ箱を空にする
回答：CD
新しい質問184
どの2つのツールを使用して、listener.oraファイル内の静的なサービス情報を構成できますか？
A. Oracle Net Manager
B. Oracle Enterprise Managerクラウド制御
C. Oracle Netコンフィギュレーション・アシスタント
D.リスナー制御ユーティリティー（LSNRCTL）
E. Oracle Enterprise Manager Database Express
回答：AC
新しい質問185
データベースでは、STATISTICS_LEVELパラメータはTYPICALに設定され、自動ワークロードリポジトリ（AWR）スナップショットは30分ごとに取得されます。自動データベース診断モニタ（ADDM）について、どちらの記述が正しいですか？
A.各AWRスナップショットが作成された後に実行され、分析には少なくとも2つのスナップショットが必要です。
B.非アイドル状態のすべてのユーザーセッションの待機時間とCPU時間を分析して、データベースのパフォーマンスを測定します。
C.必要に応じて他の顧問を呼びますが、使用する顧問についての勧告はしません。
D.最新のスナップショットを常に分析のためのベースラインスナップショットと比較します。
" . 90069) ((marker . 15876) . -757) ((marker) . -757) ((marker . 89118) . -199) ((marker . 89118) . -757) ((marker) . -757) nil ("E.分析には少なくとも4つのAWRスナップショットが必要です。
回答：AB
新しい質問186
従来のnonOMFファイルシステムでは、デフォルトで高速リカバリ領域にどの3つのファイルタイプが格納されていますか？
A.オンラインREDOログファイル
B.パラメータファイル
現在の制御ファイルのC.多重コピー
D.アーカイブログファイル
E.データアーカイブファイルのフラッシュバック
F.フラッシュバックログ
回答：ACD
新しい質問187
データベース構成アシスタント（DBCA）を使用して、デフォルトの8KB以外のブロック・サイズのデータ​​ベースを作成する場合。どちらのオプションを使用する必要がありますか？
A.カスタムデータベーステンプレート
B.データウェアハウスデータベーステンプレート
C.データファイルを格納する自動ストレージ管理（ASM）
D.データファイルの格納のためのファイルシステム
答え：A
新しい質問188
データベース構成アシスタント（DBCA）について、どの2つの記述が当てはまりますか？
A.新しい表領域を追加するために使用できます。
B.既存のOracleデータベースを新しいホストにコピーし、新しいホストに必要なパッチを適用するために使用できます
C.自動ストレージ管理（ASM）ディスク・グループを構成できます
D.既存のデータベースからデータベーステンプレートを作成するために使用できます
E. SQLデータベース作成スクリプトを生成できます
回答：CD
新しい質問189
Enterprise Manger Database Express（EM Express）を設定するための2つの前提条件を特定します。
A. APEX_PUBLIC_USERロールをSYSMANユーザーに付与します。
B. Oracle HTTP Serverのインストール
" . 90826) ((marker) . -798) ((marker) . -798) 91624 nil ("C. DBMS_XDB_CONFIG.SETHTTPPORTプロシージャを使用して、Oracle HTTP Serverのポート番号を構成します
D. TCP / IPプロトコル用に少なくとも1つのディスパッチャを構成する
E. EM Expressの管理としてSYSDBA権限を持つSYSMANユーザーを作成します。
回答：CE
新しい質問190
自動メンテナンスタスクの一環として、どの3つのツールまたはタスクがデフォルトで実行されますか？
A. SQLアクセスアドバイザ
B.オプティマイザ統計収集
C.セグメントアドバイザー
D.自動SQLチューニング・アドバイザ
E.自動データベース診断モニタ
回答：BCD
新しい質問191
自動化された保守タスクに関して、どの3つのステートメントが当てはまりますか？
A.事前定義された保守タスクは、自動オプティマイザ統計収集、自動セグメント・アドバイザの実行、自動SQLチューニング・アドバイザの実行で構成されます
B.すべてのタスクの実行履歴を格納するために、SYSTEM表領域にリポジトリが維持されている
これらは、低いシステム負荷の期間中に発生する予定の所定の時間間隔で動作する
D. Oracle Schedulerジョブは、メンテナンス・ウィンドウで実行するようにスケジュールされている各メンテナンス・タスクごとに作成されます
E.定義されたすべての保守タスクが完了するまで、保守ウィンドウが自動的に延長されます
回答：ACD
" . 91624) ((marker) . -644) 92268 nil ("
I think – only C, becouse A is not true (DBA!=SYSDBA).
0-062 Exam Questions and Answers Updated Recently (12/July/2016):
" . 89620) ((marker) . -122) 89742 nil ("B" . -89075) nil ("A, " . 89075) ((marker) . -3) 89078 nil ("
Explanation:
Using the DBCA to Create a Database (continued)
3. Database Identification: Enter the Global Database Name in The form
database_name.domain_name, and the system identifier (SID). The SID defaults lo the database
name and uniquely identifies the instance associated with the database.
4. Management Options: Use this page to set up your database so that it can be managed with
Oracle Enterprise Manager. Select the default: “Configure the Database with Enterprise Manager.”
Optionally, this page allows you to configure alert notifications and daily disk backup area settings.
Note: Yon must configure the listener before you can configure Enterprise Manager (as shown
earlier).
D
A !!!
https://docs.oracle.com/database/121/LADBI/rev_precon_db.htm#i1027493
The Oracle Database software identifies a database by its global database name. A global database name consists of the database name and database domain. Usually, the database …" . 88705) ((marker) . -947) 89652 nil ("
C
You can issue the ALTER TABLESPACE…READ ONLY statement while the database is processing transactions. After the statement is issued, the tablespace is put into a transitional read-only state. No transactions are allowed to make further changes (using DML statements) to the tablespace. If a transaction attempts further changes, it is terminated and rolled back. However, transactions that already made changes and that attempt no further changes are allowed to commit or roll back.
It is D !!!
Test it yourself, you will get a ORA-00372 for every further DML that modifys cust table and the transaction is not terminated nor rolled back automatically.
DDL fails with
ORA-00054: resource busy and acquire with NOWAIT specified or timeout expired
D is correct!
The command hangs until a commit or rollback is entered
D – really correct, i tested.
I have a sure that the answer is C!
Any subsequent transaction to the command is not allowed. Even the user who started the previous transactions command.
You cant do anything except commit or rollback then D is the answer right?" . 88119) ((marker) . -1078) 89197 nil ("
D
It is B !!!
Standard database auditing does not record old and new values as requested here. With the standard you will only see the statements with the new values (e.g. in case of an update). To get the result you have to implement triggers.
Sadly I could not find some good official statement but a good summary could be found here: http://www.myoracletips.in/2013_02_01_archive.html
B, no doubts
Every the moment in a when we opt for blogs that we study. Listed below are the newest web-sites that we opt for.
Why not FGA? https://docs.oracle.com/cd/B19306_01/network.102/b14266/cfgaudit.htm#i1011302" . 87224) ((marker) . -606) 87830 nil ("
b E
B, C
I think the answer is B, C
Both answers are stated in this ToadWorld wiki:
http://www.toadworld.com/platforms/oracle/w/wiki/1525.automated-database-diagnostic-monitor-addm-addm.aspx
" . 86544) ((marker) . -192) 86736 nil ("
Explanation:
A: You can create and rebuild indexes online. Therefore, you can update base
tables at
the same time you are building or rebuilding indexes on that table. You can perform
DML operations while the index build is taking place, but DDL operations are not
allowed. Parallel execution is not supported when creating or rebuilding an index
online.
D: Moving (Rebuilding) Index-Organized Tables
Because index-organized tables are primarily stored in a B-tree index, you can
encounter fragmentation as a consequence of incremental updates. However, you can
use the ALTER TABLE…MOVE statement to rebuild the index and reduce this
fragmentation.
C: If a table can be compressed in the new tablespace, also it can be compressed in the same
tablespace.
Incorrect:
Not B, not E: Local and Global indexes can be automatically rebuild with UPDATE INDEXES when
you move the table.
D E A
A, C, D
http://docs.oracle.com/database/121/ADMIN/tables.htm#ADMIN13948
Wir sind Ihr Partner fuer hochwertigen Zahnersatz in Ludwigsburg – Zahnarztpraxis Dr. Jacobi-Haumer
http://www.zkRCZC3urT.com/zkRCZC3urT" . 86012) ((marker) . -1093) 87105 nil ("

Explanation:
* Multiprocess and Multithreaded Oracle Database Systems
Multiprocess Oracle Database (also called multiuser Oracle Database) uses several processes to
run different parts of the Oracle Database code and additional Oracle processes for the
users—either one process for each connected user or one or more processes shared by multiple
users. Most databases are multiuser because a primary advantage of a database is managing
data needed by multiple users simultaneously.
Each process in a database instance performs a specific job. By dividing the work of the database
and applications into several processes, multiple users and applications can connect to an
instance simultaneously while the system gives good performance.
* In previous releases, Oracle processes did not run as threads on UNIX and Linux systems.
Starting in Oracle Database 12c, the multithreaded Oracle Database model enables Oracle
processes to execute as operating system threads in separate address spaces.
BCF
BCF
" . 85166) ((marker) . -1002) 86168 nil ("
B
http://docs.oracle.com/database/121/DBSEG/audit_config.htm#DBSEG401
About Auditing Oracle Recovery Manager Events
Unlike other Oracle Database components, you do not create a unified audit policy for Oracle Recovery Manager events. The UNIFIED_AUDIT_TRAIL data dictionary view has a set of fields, whose names begin with RMAN_, that automatically record Recovery Manager-related events
B
" . 84840) ((marker) . -391) 85231 nil ("
" . -84595) ((marker . 15876) . -1) nil ("
Explanation:
AC (not E): 
The md_restore command allows you to restore a disk group from the metadata created by the
md_backup command.
md_restore can’t restore data, only metadata.

http://docs.oracle.com/cd/E11882_01/server.112/e18951/asm_util004.htm#OSTMG01644
cf" . 84596) ((marker) . -267) 84863 nil ("
Explanation:
Supported services, that is, the services to which the listener forwards client
requests, can be configured in the listener.ora file or this information can be dynamically registered
with the listener. This dynamic registration feature is called service registration. The registration is
performed by the PMON process—an instance background process—of each database instance
that has the necessary configuration in the database initialization parameter file. Dynamic service
registration does not require any configuration in the listener.ora file.
Incorrect:
Not B: Service registration reduces the need for the SID_LIST_listener_name parameter setting,
which specifies information about the databases served by the listener, in the listener.ora file.
Note:
* Oracle Net Listener is a separate process that runs on the database server computer. It receives
incoming client connection requests and manages the traffic of these requests to the database
server.
* A remote listener is a listener residing on one computer that redirects connections to a database
instance on another computer. Remote listeners are typically used in an Oracle Real Application
Clusters (Oracle RAC) environment. You can configure registration to remote listeners, such as in
the case of Oracle RAC, for dedicated server or shared server environments.

Answer C is not correct as PMON used to Listener Registration Prior Rel 12c. From 12c LREG process does Listener Registration
ADE
As stated by winner2001 – in 12c LREG is reponsible for dynamic registration.
Therefore D because:
As a minimum the listener.ora file must include a section for one listener that states its name, the protocol and the listening address it will use.
Answer : A
Ref : From 12c onwards service registration with listener is being done by LGRE background process not PMON
https://docs.oracle.com/database/121/REFRN/GUID-86184690-5531-405F-AA05-BB935F57B76D.htm#REFRN104
Option D is correct but not very appropriate, as per below url
https://docs.oracle.com/database/121/NETAG/listenercfg.htm#NETAG292
Overview of Oracle Net Listener
A listener is configured with one or more listening protocol addresses, information about supported services, and parameters that control its runtime behavior. The listener configuration is stored in a configuration file named listener.ora.
Because the configuration parameters have default values, it is possible to start and use a listener with no configuration.
So as per above statement from Oracle doc its not mandatory to configure listener with a protocol. It would pick default configuration" . 83314) ((marker) . -2602) 85916 nil ("
" . -82661) ((marker . 15876) . -1) nil ("I dont seem to find this statements in the offcial study book for this exam. How can this be ?
BD
A and B
I chose C and D on the exam, and it was wrong.
A and B
http://docs.oracle.com/cd/B28359_01/server.111/b28310/tspaces010.htm#ADMIN11384
BD" . 82662) ((marker) . -243) 82905 nil ("Explanation:
C (not D): CONS_VPD_AUTO
Used to indicate to copy VPD policies automatically
* DBMS_RLS.ADD_POLICY
/ The DBMS_RLS package contains the fine-grained access control administrative interface, which
is used to implement Virtual Private Database (VPD).DBMS_RLS is available with the Enterprise
Edition only.
Note:
* CONS_USE_PK and CONS_USE_ROWID are constants used as input to the “options_flag”
parameter in both the START_REDEF_TABLE Procedure and CAN_REDEF_TABLE Procedure.
CONS_USE_ROWID is used to indicate that the redefinition should be done using rowids while
CONS_USE_PK implies that the redefinition should be done using primary keys or pseudoprimary keys (which are unique keys with all component columns having NOT NULL constraints).
* DBMS_REDEFINITION.START_REDEF_TABLE
To achieve online redefinition, incrementally maintainable local materialized views are used.
These logs keep track of the changes to the master tables and are used by the materialized views
during refresh synchronization.
* START_REDEF_TABLE Procedure
Prior to calling this procedure, you must manually create an empty interim table (in the same
schema as the table to be redefined) with the desired attributes of the post-redefinition table, and
then call this procedure to initiate the redefinition.
AC is correct
All cloned referential constraints involving the interim tables will be created disabled (they will be automatically enabled after the redefinition) and all triggers on interim tables will not fire till the redefinition is completed. After the redefinition is complete, the cloned objects will be renamed to the corresponding pre-redefinition names of the objects (from which they were cloned from).
hi,
It seems this statement isnt in the 1Z0-062 book aswell. Am i missing something when trying to study for this certificate ?
I don’t know the book. But I had this question in my exam, too." . 82158) ((marker) . -1901) 84059 nil ("
Explanation:
* Monitoring database operations
Real-Time Database Operations Monitoring enables you to monitor long running
database tasks such as batch jobs, scheduler jobs, and Extraction, Transformation,
and Loading (ETL) jobs as a composite business operation. This feature tracks the
progress of SQL and PL/SQL queries associated with the business operation being
monitored. As a DBA or developer, you can define business operations for
monitoring by explicitly specifying the start and end of the operation or implicitly
with tags that identify the operation.
D
D
" . 81580) ((marker) . -570) 82150 nil ("/ The management and security of the audit trail is also improved by having it in single audit trail.
/ You can create named audit policies that enable you to audit the supported components listed at
the beginning of this section, as well as SYS administrative users. Furthermore, you can build
conditions and exclusions into your policies.
* Oracle Database 12c Unified Auditing enables selective and effective auditing inside the Oracle
database using policies and conditions. The new policy based syntax simplifies management of
auditing within the database and provides the ability to accelerate auditing based on conditions.
* The new architecture unifies the existing audit trails into a single audit trail, enabling simplified
management and increasing the security of audit data generated by the database.
A, B, E
B, D and E
Why not A?
I could not find any doc that proofs that.
If you can, please tell us here.
Why B?
http://docs.oracle.com/database/121/DBSEG/auditing.htm#CHDICFCE
> Overall auditing performance is greatly improved. The default mode …
Why not C?
http://docs.oracle.com/database/121/DBSEG/audit_admin.htm#CHDIHJBB
> In the event of an instance crash or during SHUTDOWN ABORT operations, there is a chance that some audit records may be lost. If this is a …
It would be possible to make it zero-loss, but this is not default and would cause performance decrease. => Not the best answer therefor.
Why D?
http://docs.oracle.com/database/121/DBSEG/auditing.htm#CHDDGDHB
>The unified audit trail, which resides in a read-only table in the AUDSYS schema in the SYSAUX tablespace, makes this …
Not even SYS is able to modify audit data.
Why E?
http://www.oracle.com/webfolder/technetwork/tutorials/obe/db/12c/r1/security/sec_uni_audit/sec_uni_audit.html
See example with RMAN. RMAN is audited by default.
B D E" . 80355) ((marker) . -1829) 82184 nil ("
Explanation:
11G has a new feature called Invisible Indexes. An invisible index is invisible to the
optimizer as default. Using this feature we can test a new index without effecting the execution
plans of the existing sql statements or we can test the effect of dropping an index without dropping
it.
Please fix the typo in A. Should be ORD_CUSTOMER_IX2
AE
A E
AE
" . 77866) ((marker) . -366) 78232 nil ("
Explanation:
CREATE DISKGROUP NORMAL REDUNDANCY
* For Oracle ASM to mirror files, specify the redundancy level as NORMAL REDUNDANCY (2-way
mirroring by default for most file types) or HIGH REDUNDANCY (3-way mirroring for all files).
D
D" . 77163) ((marker) . -237) 77400 nil ("
Explanation:
Oracle Database Advanced Application Developer’s Guide 11g, Using Oracle
Flashback Technology

correct answers are CD.
http://docs.oracle.com/database/121/ADFNS/adfns_flashback.htm#ADFNS610
Enable supplemental logging is prerequisites for flashback transaction query feature. So it may not necessary for performing a flashback transaction? I’m not very sure
C, D
Following prerequisites must be met to perform a Flashback Transaction on an Oracle Database 12c database:
– The database must be in ARCHIVELOG mode
– Supplemental logging must be enabled in the database using ALTER DATABASE ADD SUPPLEMENTAL LOG DATA
– A supplemental log data primary key should be created using the statement ALTER DATABASE ADD SUPPLEMENTAL LOG DATA (PRIMARY KEY) COLUMNS
– The user performing the Flashback Transaction must have the SELECT ANY TRANSACTION privilege
– The user should have the EXECUTE privilege on DBMS_FLASHBACK
– The user should also have appropriate DML privileges on the tables (such as INSERT/UPDATE/DELETE)
So the correct answer should be C and D.
C D" . 76166) ((marker) . -1069) 77235 nil ("
Explanation:
You can use SQL*Loader to do the following:
/ (A) Manipulate the data before loading it, using SQL functions.
/ (D) Generate unique sequential key values in specified columns.
etc:
/ Load data into multiple tables during the same load session.
/ Load data across a network. This means that you can run the SQL*Loader client on a different
system from the one that is running the SQL*Loader server.
/ Load data from multiple datafiles during the same load session.
/Specify the character set of the data.
/ Selectively load data (you can load records based on the records’ values).
/Use the operating system’s file system to access the datafiles.
/ Load data from disk, tape, or named pipe.
/ Generate sophisticated error reports, which greatly aid troubleshooting.
/ Load arbitrarily complex object-relational data.
/ Use secondary datafiles for loading LOBs and collections.
/ Use either conventional or direct path loading. While conventional path loading is very flexible,
direct path loading provides superior loading performance.
Note:
* SQL*Loader loads data from external files into tables of an Oracle database. It has a powerful
data parsing engine that puts little limitation on the format of the data in the datafile.
CD
http://docs.oracle.com/cd/B19306_01/server.102/b14215/ldr_concepts.htm
C D
A is incorrect, external tables are better for transforms than SQL Loader
http://docs.oracle.com/cd/B28359_01/server.111/b28319/ldr_concepts.htm
so CD as others have said
" . 75732) ((marker) . -1492) 77224 nil ("on/off on the go.
SQL> alter system set ENABLE_DDL_LOGGING=true;
System altered.
Elapsed: 00:00:00.05
SQL>
Once it is turned on, every DDL command will be logged in the alert log file and also the log.xml
file.
The DDL log is a file that has the same format and basic behavior as the alert log, but it only contains the DDL statements issued by the database. There are two DDL logs that contain the same information. One is an XML file, and the other is a text file. The DDL log is stored in the log/ddl subdirectory of the ADR home.
http://docs.oracle.com/database/121/REFRN/refrn10302.htm#REFRN10302
i think that E is correct
c
E
https://docs.oracle.com/database/121/REFRN/refrn10302.htm#REFRN10302
I think E is not correct, cause there are two files generated when ENABLE_DDL_LOGGING is set to TRUE. One is a text file (with only the DDL commands but no dates) is located in ADR_HOME/log, another is the XML format file (with DDL commands and execution timestamp) which is located in ADR_HOME/log/ddl. But E indicates ALERT directory, which is not correct.
Answer C actually means the XML format DDL log file in ADR_HOME/log/ddl/
https://docs.oracle.com/database/121/REFRN/GUID-6FBA6147-D545-4E7D-94F0-A97EC1C721AE.htm
ENABLE_DDL_LOGGING enables or disables the writing of a subset of data definition language (DDL) statements to a DDL log.
The DDL log is a file that has the same format and basic behavior as the alert log, but it only contains the DDL statements issued by the database. The DDL log is created only for the RDBMS component and only if the ENABLE_DDL_LOGGING initialization parameter is set to true. When this parameter is set to false, DDL statements are not included in any log.
The DDL log contains one log record for each DDL statement issued by the database. The DDL log is included in IPS incident packages.
There are two DDL logs that contain the same information. One is an XML file, and the other is a text file. The DDL log is stored in the log/ddl subdirectory of the ADR home.
C" . 75382) ((marker) . -2010) 77392 nil ("
Explanation:
EM Express is built inside the database.
Note:
Oracle Enterprise Manager Database Express (EM Express) is a web-based database
management tool that is built inside the Oracle Database. It supports key performance
management and basic database administration functions. From an architectural perspective, EM
Express has no mid-tier or middleware components, ensuring that its overhead on the database
server is negligible.
D is correct.
http://www.oracle.com/technetwork/database/manageability/emx-intro-1965965.html
Why E is not correct?http://docs.oracle.com/database/121/ADMQS/pdbs.htm#ADMQS12512
Would also vote for D.
Sorry … “E” I meant.
D
Lol seriously oracle?! D and E are both correct!
It is not possible to start/stop the DB instance with EM Express….
At bottom A could be also correct, because if you install Oracle 12c the EM Express will be installed too
The question should be which one is not true……
A C D E
This is confusing – all answers are correct …
… including B(!)
It is possible, to manage different databases on the same machine.
All you have to do is configuring individual ports:
“You can use EM Express to manage a non-CDB, a CDB, or a PDB. For each non-CDB, CDB, or PDB that you want to manage using EM Express on a given host, a unique HTTPS port must be configured. A different port must be configured for each container in a CDB that you want to manage using EM Express.”" . 74165) ((marker) . -1414) 75579 nil ("a database to a time when a dropped data file existed in the database, only the data file entry is
added to the control file. You can only recover the dropped data file by using RMAN to fully restore
and recover the data file.
Oracle Database Backup and Recovery User’s Guide 12c R

F) ->
http://docs.oracle.com/database/121/BRADV/flashdb.htm#BRADV582
From that time onwards, at regular intervals, the database copies images of each altered block in every data file into the flashback logs. These block images can later be reused to reconstruct the data file contents for any moment at which logs were captured.
When you use Flashback Database to rewind a database to a past target time, the command determines which blocks changed after the target time and restores them from the flashback logs. The database restores the version of each block that is immediately before the target time. The database then uses redo logs to reapply changes that were made after these blocks were written to the flashback logs.
Redo logs on disk or tape must be available for the entire time period spanned by the flashback logs. For example, if the flashback retention target is 1 week, then you must ensure that online and archived redo logs that contain all changes for the past week are accessible. In practice, redo logs are typically needed much longer than the flashback retention target to support point-in-time recovery.
D) ->
You can use Flashback Database to reverse most unwanted changes to a database if the data files are intact. You can return a database to its state in a previous incarnation, and undo the effects of an ALTER DATABASE OPEN RESETLOGS statement
C) ->
Flashback Database uses its own logging mechanism, creating flashback logs and storing them in the fast recovery area. You can only use Flashback Database if flashback logs are available. To take advantage of this feature, you must set up your database in advance to create flashback logs.
C D F
CDF
Flashback Database
Flashback Database is similar to conventional point-in-time recovery in its effects. It enables you to return a database to its state at a time in the recent past. Flashback Database is much faster than point-in-time recovery because it does not require restoring data files from backup and requires applying fewer changes from the archived redo logs.
You can use Flashback Database to reverse most unwanted changes to a database if the data files are intact. You can return a database to its state in a previous incarnation, and undo the effects of an ALTER DATABASE OPEN RESETLOGS statement. “Rewinding a Database with Flashback Database” explains how to use the FLASHBACK DATABASE command to reverse database changes.
Flashback Database uses its own logging mechanism, creating flashback logs and storing them in the fast recovery area. You can only use Flashback Database if flashback logs are available. To take advantage of this feature, you must set up your database in advance to create flashback logs.
To enable Flashback Database, you configure a fast recovery area and set a flashback retention target. This retention target specifies how far back you can rewind a database with Flashback Database.
From that time onwards, at regular intervals, the database copies images of each altered block in every data file into the flashback logs. These block images can later be reused to reconstruct the data file contents for any moment at which logs were captured.
When you use Flashback Database to rewind a database to a past target time, the command determines which blocks changed after the target time and restores them from the flashback logs. The database restores the version of each block that is immediately before the target time. The database then uses redo logs to reapply changes that were made after these blocks were written to the flashback logs.
Redo logs on disk or tape must be available for the entire time period spanned by the flashback logs. For example, if the flashback retention target is 1 week, then you must ensure that online and archived redo logs that contain all changes for the past week are accessible. In practice, redo logs are typically needed much longer than the flashback retention target to support point-in-time recovery.
CDF" . 73655) ((marker) . -4259) 77914 (t 22854 4637 0 0) nil ("
Explanation:
The value for TBS_PERCENT_USED specifies the percentage of the tablespace quota when a
tablespace is considered full. The value for TBS_PERCENT_FREE specifies the targeted free
percentage for the tablespace. When the percentage of the tablespace quota reaches the value of
TBS_PERCENT_USED, ADO begins to move data so that percent free of the tablespace quota
approaches the value of TBS_PERCENT_FREE. This action by ADO is a best effort and not a
guarantee.
C definitely
But don’t know if B is also correct as it asks for 2.
A C
BC" . 72102) ((marker) . -546) 72648 nil ("
Explanation:
B: SYSDG administrative privilege has ability to perform Data Guard operations (including startup
and shutdown) using Data Guard Broker or dgmgrl.
D: SYSASM
The new (introduced in 11g) SYSASM role to manage the ASM instance, variable extent sizes to
reduce shared pool usage, and the ability of an instance to read from a specific disk of a diskgroup
E (Not A): SYSDBA is like a role in the sense that it is granted, but SYSDBA is a special built-in
privilege to allow the DBA full control over the database
Incorrect:
Not C: SYSKM. SYSKM administrative privilege has ability to perform transparent data encryption
wallet operations.
Note:
Use the V$PWFILE_USERS view to see the users who have been granted administrative
privileges.
BDE
Why E:
SYSBACKUP facilitates Oracle Recovery Manager (RMAN) backup and recovery operations either from RMAN or SQL*Plus.
https://docs.oracle.com/database/121/ADMIN/dba.htm#ADMIN11042
B D E
Truly no matter if someone doesn’t understand after that its up to other visitors that they will help, so here it happens.|" . 71249) ((marker) . -1064) 72313 nil ("
Explanation:
B: Data Pump can employ multiple worker processes, running in parallel, to
increase job performance.
D: For export jobs, the master table records the location of database objects within a dump file set.
/ Export builds and maintains the master table for the duration of the job. At the end of an export
job, the content of the master table is written to a file in the dump file set.
/ For import jobs, the master table is loaded from the dump file set and is used to control the
sequence of operations for locating objects that need to be imported into the target database.
A, D, E
A, B , E
ABD
I would guess A, D and E
Weird because A and E are definitley good – you can detach and attach exports and imports.
https://docs.oracle.com/cloud/latest/db121/SUTIL/dp_overview.htm#SUTIL100
And also it is definitley D
https://docs.oracle.com/cloud/latest/db121/SUTIL/dp_overview.htm#SUTIL808
> For export jobs, the master table records the location of database objects within a dump file set. Export builds and maintains the master table for the duration of the job. At the end of an export job, the content of the master table is written to a file in the dump file set.
C is not correct to me.
B sounds also very good. But you have to set PARALLEL option for this. Datapump does not do it by default.
Also the docs say:
> This execution set consists of a combination of worker processes and parallel I/O server processes. The master control process, idle workers, and worker processes acting as parallel execution coordinators in parallel I/O operations do not count toward this total. This parameter enables you to make trade-offs between resource consumption and elapsed time.
So B is not wrong to me but also not 100% correct because it uses not only “server processes” but also “worker processes”
A D E" . 70656) ((marker) . -1816) 72472 nil ("
" . -70183) ((marker . 15876) . -1) nil ("Explanation:
The alert log is a chronological log of messages and errors, and includes the
following items:
*All internal errors (ORA-600), block corruption errors (ORA-1578), and deadlock errors (ORA-60)
that occur
* Administrative operations, such as CREATE, ALTER, and DROP statements and STARTUP,
SHUTDOWN, and ARCHIVELOG statements
* Messages and errors relating to the functions of shared server and dispatcher processes
* Errors occurring during the automatic refresh of a materialized view
* The values of all initialization parameters that had nondefault values at the time the database
and instance start
Note:
* The alert log file (also referred to as the ALERT.LOG) is a chronological log of messages and
errors written out by an Oracle Database. Typical messages found in this file is: database startup,
shutdown, log switches, space errors, etc. This file should constantly be monitored to detect
unexpected messages and corruptions.
AE. C seems to me correct too.
A E
AE" . 70184) ((marker) . -985) 71169 nil ("Why E:
https://docs.oracle.com/cloud/latest/db121/ADMIN/dba.htm#ADMIN11059
> If 12, the default, the password file is created in Oracle Database 12c format. This format supports the SYSBACKUP, SYSDG, and SYSKM administrative privileges.
AE
Sorry = CE
C E" . 69658) ((marker) . -254) 69912 nil ("Explanation:
An Oracle session is sniped when you set the idle_time parameter to disconnect
inactive sessions. (It’s only like sniping on ebay in that a time is set for an action to occur.)
Oracle has several ways to disconnect inactive or idle sessions, both from within SQL*Plus via
resources profiles (connect_time, idle_time), and with the SQL*net expire time parameter. Here
are two ways to disconnect an idle session:
Set the idle_time parameter in the user profile
Set the sqlnet.ora parameter expire_time
B
MAX_IDLE_BLOCKER_TIME
http://docs.oracle.com/database/121/ADMIN/dbrm.htm#ADMIN11868
B
B" . 69006) ((marker) . -602) 69608 nil (68730 . 68731) nil ("
" . -68730) nil ("B is wrong. default tablespace cannot be dropped
C, D, E
C D E" . 68625) ((marker) . -62) 68687 nil ("BE
http://docs.oracle.com/cd/B28359_01/backup.111/b28273/rcmsynta023.htm#RCMRF194
B E
BE" . 68038) ((marker) . -88) 68126 nil ("
Explanation:
During SQL execution, if a cardinality misestimate occurs, then the database
creates SQL plan directives. During SQL compilation, the optimizer examines the query
corresponding to the directive to determine whether missing extensions or histograms exist (D).
The optimizer records any missing extensions. Subsequent DBMS_STATS calls collect statistics
for the extensions.
The optimizer uses dynamic sampling whenever it does not have sufficient statistics
corresponding to the directive. (B, not C)
E: Currently, the optimizer monitors only column groups. The optimizer does not create an
extension on expressions.
Incorrect:
Not A: SQL plan directives are not tied to a specific SQL statement or SQL ID.
Note:
* A SQL plan directive is additional information and instructions that the optimizer can use to
generate a more optimal plan. For example, a SQL plan directive can instruct the optimizer to
record a missing extension.
Only D&F are correct
F: correct. SYSAUX stores both compilation and execution stats
A: Not tied to any specific sql id.
B: Wrong. says isntructs maintenance job, which is incorrect. It instructs optimizer
E: Wrong. Instructs optimizer – not ONLY to create column group stats, it also instructs to collecting missing stats and perform dynamic sampling.
C: Wrong. Same as E, not only missing stats.
B, D, E
http://docs.oracle.com/database/121/TGSQL/tgsql_statscon.htm#TGSQL347
…Currently, the optimizer monitors only column groups…
B D E" . 67333) ((marker) . -1478) 68811 nil ("
" . -66723) ((marker . 15876) . -1) nil ("
Explanation:
Tracing information is present in multiple trace files and you must use the trcsess
tool to collect it into a single file.
Incorrect:
Not 1: Parameter service_name
Name of the service for which tracing is enabled.
module_name
Name of the MODULE. An optional additional qualifier for the service.
Note:
* The procedure enables a trace for a given combination of Service, MODULE and ACTION name.
The specification is strictly hierarchical: Service Name or Service Name/MODULE, or Service
Name, MODULE, and ACTION name must be specified. Omitting a qualifier behaves like a wildcard, so that not specifying an ACTION means all ACTIONs. Using the ALL_ACTIONS constant
achieves the same purpose.
* SERV_MOD_ACT_TRACE_ENABLE Procedure
This procedure will enable SQL tracing for a given combination of Service Name, MODULE and
ACTION globally unless an instance_name is specified.
* DBMS_MONITOR.SERV_MOD_ACT_TRACE_ENABLE(
service_name IN VARCHAR2,
module_name IN VARCHAR2 DEFAULT ANY_MODULE,
action_name IN VARCHAR2 DEFAULT ANY_ACTION,
waits IN BOOLEAN DEFAULT TRUE,
binds IN BOOLEAN DEFAULT FALSE,
instance_name IN VARCHAR2 DEFAULT NULL);
Run TKPROF on each individual trace file, producing several formatted output files, one for each session.
Concatenate the trace files, and then run TKPROF on the result to produce a formatted output file for the entire instance.
Run the TRCSESS command-line utility to consolidate tracing information from several trace files, then run TKPROF on the result.
B" . 66724) ((marker) . -1507) 68231 nil ("
Explanation:
C: Setting the CONTROL_MANAGEMENT_PACK_ACCESS initialization parameter
to DIAGNOSTIC+TUNING (default) enables monitoring of database operations. Real-Time SQL
Monitoring is a feature of the Oracle Database Tuning Pack.
Note:
* The DBMS_SQL_MONITOR package provides information about Real-time SQL Monitoring and
Real-time Database Operation Monitoring.
*(not B) BEGIN_OPERATION Function
starts a composite database operation in the current session.
/ (E) FORCE_TRACKING – forces the composite database operation to be tracked when the
operation starts. You can also use the string variable ‘Y’.
/ (not A) NO_FORCE_TRACKING – the operation will be tracked only when it has consumed at
least 5 seconds of CPU or I/O time. You can also use the string variable ‘N’.
CE
C E
CE
" . 65864) ((marker) . -786) 66650 nil ("
A,B,C,G
Oh sorry, I was wrong!
Correct answer: A,B,E,G
*Not C because “Specifies the size of each backup section produced during a data file or data file copy backup.” archivelogs are no datafiles and no file copys
*Not D because tempfiles are never backed up
ora600 is right
http://docs.oracle.com/database/121/BRADV/rcmbckba.htm#BRADV8003
A
B (possible from 12.1)
E
G
A B E G
" . 65118) ((marker) . -379) 65497 nil ("
" . -64598) ((marker . 15876) . -1) nil ("
Explanation:
Unlike unusable indexes, an invisible index is maintained during DML statements.
Note:
* Oracle 11g allows indexes to be marked as invisible. Invisible indexes are maintained like any
other index, but they are ignored by the optimizer unless the
OPTIMIZER_USE_INVISIBLE_INDEXES parameter is set to TRUE at the instance or session
level. Indexes can be created as invisible by using the INVISIBLE keyword, and their visibility can
be toggled using the ALTER INDEX command.
A,E
A E
why?" . 64599) ((marker) . -498) 65097 nil ("
Explanation:
The Segment Advisor generates the following types of advice:
* If the Segment Advisor determines that an object has a significant amount of free space, it
recommends online segment shrink. If the object is a table that is not eligible for shrinking, as in
the case of a table in a tablespace without automatic segment space management, the Segment
Advisor recommends online table redefinition (C).
* (D) If the Segment Advisor encounters a table with row chaining above a certain threshold, it
records that fact that the table has an excess of chained rows.

Correct answer: A,D,E
A is correct not B because shrink needs ASSM enabled which is not the case with dictionary managed tbs.
E is correct not C because localy managed (or free list managed) tablespaces allow shrink which is the better choice.
Not B (dictionary managed tablespaces) and Not E (free list managed tables) – The Segment Shrink option is available only to the segments belonging to local extent management tablespaces with automatic segment space management.
C is possible – locally managed tablespaces can use either manual or automatic segment space management, in the case of manual segment space management, Segment Advisor will not be able to advise Segment Shrink option and therefore Online Table Redefinition advise is possible.
So I think the correct answer i A,C,D
A C D
I am agree with conclusion the Mike Yeap. see doc oracle/concept/logical storage structure tablespace.
ACD
Regarding D: It says “detect and advise” but from the link:
https://docs.oracle.com/database/121/ADMIN/schema.htm#ADMIN10120
“For row chaining advice, the Automatic Segment Advisor generates findings only, and not recommendations”.
Which means it only detects, not advice." . 64039) ((marker) . -1746) 65785 nil ("
Explanation:
Note:
* Oracle 12c now provides the ability to index a subset of partitions and to exclude the others.
Local and global indexes can now be created on a subset of the partitions of a table. Partial Global
indexes provide more flexibility in index creation for partitioned tables. For example, index
segments can be omitted for the most recent partitions to ensure maximum data ingest rates
without impacting the overall data model and access for the partitioned object.
Partial Global Indexes save space and improve performance during loads and queries. This
feature supports global indexes that include or index a certain subset of table partitions or
subpartitions, and exclude the others. This operation is supported using a default table indexing
property. When a table is created or altered, a default indexing property can be specified for the
table or its partitions." . 63435) ((marker) . -887) 64322 nil ("A: Below we see a case where we set the row archival visibility parameter to “all”
thereby allowing us to see all of the rows that have been logically deleted:
alter session set row archival visibility = all;
We can then turn-on row invisibility back on by changing row archival visibility = “active”:
alter session set row archival visibility = all;
B: To use ora_archive_state as an alternative to deleting rows, you need the following settings and
parameters:
1. Create the table with the row archival clause
create table mytab (col1 number, col2 char(200)) row archival;
2. Now that the table is marked as row archival, you have two methods for removing rows, a
permanent solution with the standard delete DML, plus the new syntax where you set
ora_archive_state to a non-zero value:
update mytab set ora_archive_state=2 where col2=’FRED’; 
3. To make “invisible rows” visible again, you simply set the rows ora_archive_state to zero:
update mytab set ora_archive_state=0 where col2=’FRED’; 
Note:
* Starting in Oracle 12c, Oracle provides a new feature that allow you to “logically delete” a row in
a table without physically removing the row. This effectively makes deleted rows “invisible” to all
SQL and DML, but they can be revealed at any time, providing a sort of “instant” rollback method.
To use ora_archive_state as an alternative to deleting rows.
Maybe someone out there can confirm this but I think C,D is correct. Although B sounds correct, too.
B C D
SQL> alter table sales row archival;
Table altered.
SQL> select distinct ora_archive_state from class;
ORA_ARCHIVE_STATE
——————————————————————————–
0
Note – the column ORA_ARCHIVE_STATE is now added to the table class and is a hidden column.
SQL> update class
2 set ORA_ARCHIVE_STATE=DBMS_ILM.ARCHIVESTATENAME(1)
3 where age select distinct ora_archive_state from class;
ORA_ARCHIVE_STATE
——————————————————————————–
0
SQL> select count(*) from sales;
COUNT(*)
———-
10
SQL> alter session set row archival visibility=ALL;
Session altered.
SQL> select count(*) from sales;
COUNT(*)
———-
25
C and D" . 61703) ((marker) . -2066) 63769 nil ("18 consistent gets
0 physical reads
0 redo size
433 bytes sent via SQL*Net to client
540 bytes received via SQL*Net from client
1 SQL*Net roundtrips to/from client
0 sorts (memory)
0 sorts (disk)
0 rows processed
SQL>" . 60997) ((marker) . -217) 61214 nil ("
Explanation:
* The environment setup for tablespace encryption is the same as that for transparent data
encryption. Before attempting to create an encrypted tablespace, a wallet must be created to hold
the encryption key.
* Setting the tablespace master encryption key is a one-time activity. This creates the master
encryption key for tablespace encryption. This key is stored in an external security module (Oracle
wallet) and is used to encrypt the tablespace encryption keys.
* Before you can create an encrypted tablespace, the Oracle wallet containing the tablespace
master encryption key must be open. The wallet must also be open before you can access data in
an encrypted tablespace.
* Salt is a way to strengthen the security of encrypted data. It is a random string added to the data
before it is encrypted, causing repetition of text in the clear to appear different when encrypted.
Salt removes the one common method attackers use to steal data, namely, matching patterns of
encrypted text.
* ALT | NO SALT By default the database appends a random string, called “salt,” to the clear text
of the column before encrypting it. This default behavior imposes some limitations on encrypted
columns:
/ If you specify SALT during column encryption, then the database does not compress the data in
the encrypted column even if you specify table compression for the table. However, the database
does compress data in unencrypted columns and encrypted columns without the SALT parameter." . 56390) ((marker) . -1491) 57881 nil (55582 . 55583) nil ("
" . -55582) ((marker . 15876) . -1) nil ("D
С
C
Predicate Information (identified by operation id):
—————————————————
1 – filter(“from$_subquery$_002”.”rowlimit_$$_rownumber”<=CEIL(\"from$
_subquery$_002\".\"rowlimit_$$_total\"*20/100))
D
http://docs.oracle.com/database/121/LNPLS/release_changes.htm#LNPLS113
Marc is right. Please refer to the link he posted.
D is correct.
" . 55583) ((marker) . -329) 55912 nil ("
Explanation:
A: In a cumulative level 1 backup, RMAN backs up all the blocks used since the
most recent level 0 incremental backup.
E: Oracle Block Change Tracking
Once enabled; this new 10g feature records the modified since last backup and stores the log of it
in a block change tracking file using the CTW (Change Tracking Writer) process. During backups
RMAN uses the log file to identify the specific blocks that must be backed up. This improves
RMAN’s performance as it does not have to scan whole datafiles to detect changed blocks.
Logging of changed blocks is performed by the CTRW process which is also responsible for
writing data to the block change tracking file.
Note:
* An incremental level 0 backup backs up all blocks that have ever been in use in this database.
Correct answer: C,D,E
C not A because the only situation when it noes not reduce I/O is when all blocks in the database have changed since the last incremental backup. This ist very unlikely.
D is not right. There are multiple bitmap existing.Only one copy of a block is read. It doesn’t read more than one copy.
I never see the block change tracking file is backed up. I am not sure whether B is correct or not.
Should be A not C http://docs.oracle.com/cd/B19306_01/backup.102/b14192/bkup004.htm#i1032148
”
After enabling change tracking, the first level 0 incremental backup still has to scan the entire datafile, as the change tracking file does not yet reflect the status of the blocks.
“
CDE or ADE
A D E" . 55004) ((marker) . -1490) 56494 nil ("
Explanation:
About Startup Dependencies
Oracle Restart ensures that Oracle components are started in the proper order, in accordance with
component dependencies. For example, if database files are stored in Oracle ASM disk groups,
then before starting the database instance, Oracle Restart ensures that the Oracle ASM instance
is started and the required disk groups are mounted. Likewise, if a component must be shut down,
Oracle Restart ensures that dependent components are cleanly shut down first.
Oracle Restart also manages the weak dependency between database instances and the Oracle
Net listener (the listener): When a database instance is started, Oracle Restart attempts to start
the listener. If the listener startup fails, then the database is still started. If the listener later fails,
Oracle Restart does not shut down and restart any database instances.
http://docs.oracle.com/cd/E16655_01/server.121/e17636/restart.htm#ADMIN12710
yes, it’s B
Question is asking; what is ‘Oracle High Availability Services auto start is enabled’?
It is not asking Oracle Restart behavior. I think choice A
B
B
http://docs.oracle.com/database/121/ADMIN/restart.htm#ADMIN12710
Oracle Restart also manages the weak dependency between database instances and the Oracle Net listener (the listener): When a database instance is started, Oracle Restart attempts to start the listener. If the listener startup fails, then the database is still started. If the listener later fails, Oracle Restart does not shut down and restart any database instances.
" . 53980) ((marker) . -1545) 55525 nil ("
Explanation:
A: In certain situations, you may want to exclude selected columns or tables from
scanning or conversion steps of the migration process.
D: Exceed column limit
The cell data will not fit into a column after conversion.
E: Need conversion
The cell data needs to be converted, because its binary representation in the
target character set is different than the representation in the current character
set, but neither length limit issues nor invalid representation issues have been
found.
* Oracle Database Migration Assistant for Unicode (DMU) is a unique next-generation migration
tool providing an end-to-end solution for migrating your databases from legacy encodings to
Unicode.
Incorrect:
Not C: The release of Oracle Database must be 10.2.0.4, 10.2.0.5, 11.1.0.7, 11.2.0.1, or later.
ADE
A D E
A D E
http://docs.oracle.com/cd/E71288_01/DUMAG/ch2_getting_started.htm#DUMAG128
==> Overview of Database Requirements" . 53098) ((marker) . -931) 54029 nil ("A.
The valid time columns employee_time_start and employee_time_end are automatically created.
B.
The same statement may filter on both transaction time and valid temporal time by using the AS OF TIMESTAMP and PERIOD FOR clauses.
C.
The valid time columns are not populated by the Oracle Server automatically.
D.
The valid time columns are visible by default when the table is described.
E.
Setting the session valid time using DBMS_FLASHBACK_ARCHIVE.ENABLE_AT_VALID_TIME sets the visibility for data manipulation language (DML), data definition language (DDL), and queries performed by the session.

Explanation:
A: To implement Temporal Validity(TV), 12c offers the option to have two date
columns in that table which is having TV enabled using the new clause Period For in the Create
Table for the newly created tables or in the Alter Table for the existing ones. The columns that are
used can be defined while creating the table itself and will be used in the Period For clause or you
can skip having them in the table’s definition in the case of which, the Period For clause would be
creating them internally.
E: ENABLE_AT_VALID_TIME Procedure
This procedure enables session level valid time flashback.
A wide variety of quality advise on this great site,
need a steam shower unit within my bathroom
AC
ABE
ABC
raspberry ketone plus
http://www.XquielQMVW.com/XquielQMVW
E is wrong, no DDL" . 52635) ((marker) . -1393) 54028 nil ("SQL> truncate table test;
Table truncated.
SQL> SELECT * FROM test AS OF TIMESTAMP TO_TIMESTAMP (‘2015-09-03 16:10:57’, ‘YYYY-MM-DD HH24:MI:SS’);
C1
———-
6
7
SQL> select * from test;
no rows selected
SQL> select * from v$version;
BANNER
——————————————————————————–
CON_ID
———-
Oracle Database 12c Enterprise Edition Release 12.1.0.2.0 – 64bit Production
C
Option C is correct.
Ref : I think people have misinterpreted the Oracle doc
https://docs.oracle.com/database/121/ADFNS/adfns_flashback.htm#ADFNS640
Flashback Data Archive supports only these DDL statements:
ALTER TABLE statement that does any of the following:
Adds, drops, renames, or modifies a column
Adds, drops, or renames a constraint
Drops or truncates a partition or subpartition operation
TRUNCATE TABLE statement
RENAME statement that renames a table
………
.
……………..
C

Answer = C
C
https://docs.oracle.com/database/121/ADFNS/adfns_flashback.htm#ADFNS640
Flashback Data Archive supports only these DDL statements:
•ALTER TABLE statement that does any of the following:
◦Adds, drops, renames, or modifies a column
◦Adds, drops, or renames a constraint
◦Drops or truncates a partition or subpartition operation
•TRUNCATE TABLE statement
•RENAME statement that renames a table" . 50834) ((marker) . -1238) 52072 nil ("
Explanation:
* SYS_CONTEXT
This is a twist on the SYS_CONTEXT function as it does not use USERENV. With this usage
SYS_CONTEXT queries the list of the user’s current default roles and returns TRUE if the role is
granted.
Example:
SYS_CONTEXT(‘SYS_SESSION_ROLES’, ‘SUPERVISOR’)
conn scott/tiger@pdborcl
SELECT sys_context(‘SYS_SESSION_ROLES’, ‘RESOURCE’)
FROM dual;
SYS_CONTEXT(‘SYS_SESSION_ROLES’,’SUPERVISOR’)
———————————————FALSE
conn sys@pdborcl as sysdba
GRANT resource TO scott;
conn scott/tiger@pdborcl
SELECT sys_context(‘SYS_SESSION_ROLES’, ‘RESOURCE’)
FROM dual;
SYS_CONTEXT(‘SYS_SESSION_ROLES’,’SUPERVISOR’)
———————————————TRUE
B is correct. F is wrong.
Both users SYS and SYSTEM automatically have the EXEMPT REDACTION POLICY system privilege. (SYSTEM has the EXP_FULL_DATABASE role, which includes the EXEMPT REDACTION POLICY system privilege.) This means that the SYS and SYSTEM users can always bypass any existing Oracle Data Redaction policies, and will always be able to view data from tables (or views) that have Data Redaction policies defined on them.
http://docs.oracle.com/database/121/ASOAG/redaction.htm#ASOAG360
https://docs.oracle.com/database/121/ASOAG/redaction_guidelines.htm#ASOAG360
A B D
Have you tested out this question on exam?
5.5.3 Applying the Redaction Policy Based on Database Role
To apply a Data Redaction policy based on database roles, you can use the SYS_SESSION_ROLES namespace in the SYS_CONTEXT function, which contains attributes for each role. The value of the attribute is TRUE if the specified role is enabled for the querying application user; the value is FALSE if the role is not enabled.
For example, suppose you wanted only supervisors to be allowed to see the actual data. Example 5-2 shows how to use the DBMS_REDACT.ADD_POLICY expression parameter to set the policy to show the actual data to any application user who has the supervisor role enabled, but redact the data for all of the other application users.
Example 5-2 Applying a Data Redaction Policy by Database Role
expression => ‘SYS_CONTEXT(”SYS_SESSION_ROLES”,”SUPERVISOR”) = ”FALSE”’
ACF
A,B,C.
A,B : SYS and SYSTEM by default have the EXEMPT REDACTION POLICY system privilege. (SYS and SYSTEM has the DBA role which includes EXP_FULL_DATABASE role, which includes the EXEMPT REDACTION POLICY system privilege.)
SELECT * FROM dba_sys_privs WHERE privilege=’EXEMPT REDACTION POLICY’;
SELECT * FROM dba_role_privs WHERE granted_role IN (‘EXP_FULL_DATABASE’,’DBA’);
C : if the MGR role is set (granted+enabled) in the SCOTT session, then SYS_CONTEXT(‘SYS_SESSION_ROLES,’MGR’)=TRUE, then policy expression accept FALSE and does not redact data this session." . 49530) ((marker) . -2675) 52205 nil ("
Explanation:
* The ORA_DATABASE_PARAMETER policy audits commonly used Oracle
Database parameter settings. By default, this policy is not enabled.

Only E is correct.
If using EXCEPT clause, it’s overwrite.
If using BY clause, It’s cumulative.
So the audit policy will apply to all three users.
Correct A, B ( I tested out )
AUDIT POLICY ORA_DATABASE_PARAMETER BY SCOTT;
AUDIT POLICY ORA_DATABASE_PARAMETER BY SYS, SYSTEM;
SELECT * FROM AUDIT_UNIFIED_ENABLED_POLICIES order by 1,2;
USER_NAME POLICY_NAME ENABLED_ SUC FAI
———— ——————————– ——– — —
SCOTT ORA_DATABASE_PARAMETER BY YES YES
SYS ORA_DATABASE_PARAMETER BY YES YES
SYSTEM ORA_DATABASE_PARAMETER BY YES YES
Your example shows that (E) is correct. Both columns (“SUC” and “FAI”) show a yes.
I would go with A and E.
A, E
For which database “users” and for which executions is the “audit policy now active”? Select “two”.
A.
SYS, SYSTEM
B.
SCOTT
A B E
I agree with Marc.
John’s query returned all three users (sys, system & scott) => A & B are correct.
Again referring to John’s query, it shows that both success and failed returns TRUE => E is also correct.
/Niels" . 48962) ((marker) . -1121) 50083 nil ("A, B, E
A B E
ABD
refer to Domingo;
Lack of statement reuse
Statements not using bind variables
Insufficient size of application cursor cache
Cursors closed explicitly after each execution
Frequent logins and logoffs
Underlying object structure being modified (for example truncate)
Shared pool too small
ADE
A: Shared pool too small
D: Frequent logins and logoffs
E:Being read by one session while being modified by another session
docs:
http://docs.oracle.com/database/121/CNCPT/consist.htm#CNCPT1357
http://docs.oracle.com/database/121/TGDBA/pfgrf_instance_tune.htm#TGDBA94516" . 48559) ((marker) . -579) 49138 nil ("A: Merge Multiple Partitions:
The new “ALTER TABLE … MERGE PARTITIONS ” help merge multiple partitions or
subpartitions with a single statement. When merging multiple partitions, local and global index
operations and semantics for inheritance of unspecified physical attributes are the same for
merging two partitions.
B: Drop Multiple Partitions:
The new “ALTER TABLE … DROP PARTITIONS ” help drop multiple partitions or subpartitions
with a single statement.
Example:
view plaincopy to clipboardprint?
SQL> ALTER TABLE Tab_tst1 DROP PARTITIONS 
Tab_tst1_PART5, Tab_tst1_PART6, Tab_tst1_PART7; 
Table altered 
SQL> 
Restrictions :
– You can’t drop all partitions of the table.
– If the table has a single partition, you will get the error: ORA-14083: cannot drop the only partition
of a partitioned.
A B F
“E” is correct:
SQL> CREATE TABLE t1
2 (id NUMBER,
description VARCHAR2( 3 50),
created_date 4 DATE)
PARTITION BY RANGE (created_d 5 ate)
6 (PARTITION part_2014 VALUES LESS THAN (TO_DATE(’01/01/2015′, ‘DD/MM/YYYY’)));
Table created.
SQL> ALTER TABLE t1 RENAME PARTITION part_2014 TO part_2016;
Table altered.
A,B,E
" . 48110) ((marker) . -1122) 49232 nil ("ADE
A D E" . 47593) ((marker) . -9) 47602 nil ("
Explanation:
C: During the first execution of a SQL statement, an execution plan is generated as
usual.
D: if multi-column statistics are not present for the relevant combination of columns, the optimizer
can fall back on cardinality feedback.
(not B)* Cardinality feedback. This feature, enabled by default in 11.2, is intended to improve plans
for repeated executions.
optimizer_dynamic_sampling
optimizer_features_enable
* dynamic sampling or multi-column statistics allow the optimizer to more accurately estimate
selectivity of conjunctive predicates.
Note:
* OPTIMIZER_DYNAMIC_SAMPLING controls the level of dynamic sampling performed by the
optimizer.
Range of values. 0 to 10
* Cardinality feedback was introduced in Oracle Database 11gR2. The purpose of this feature is to
automatically improve plans for queries that are executed repeatedly, for which the optimizer does
not estimate cardinalities in the plan properly. The optimizer may misestimate cardinalities for a
variety of reasons, such as missing or inaccurate statistics, or complex predicates. Whatever the
reason for the misestimate, cardinality feedback may be able to help.
A,C. During the first execution of a SQL statement, an execution plan is generated as usual. During optimization, certain types of estimates that are known to be of low quality (for example, estimates for tables which lack statistics or tables with complex predicates) are noted, and monitoring is enabled for the cursor that is produced. If cardinality feedback monitoring is enabled for a cursor, then at the end of execution, some of the cardinality estimates in the plan are compared to the actual cardinalities seen during execution. If some of these estimates are found to differ significantly from the actual cardinalities, the correct estimates are stored for later use. The next time the query is executed, it will be optimized again, and this time the optimizer uses the corrected estimates in place of its usual estimates.
D. In some cases, there are other techniques available to improve estimation; for instance, dynamic sampling or multi-column statistics allow the optimizer to more accurately estimate selectivity of conjunctive predicates. In cases where these techniques apply, cardinality feedback is not enabled.
A C D" . 47070) ((marker) . -2287) 49357 nil (46293 . 46295) nil ("

Explanation:
E: Performance is improved by load balancing across multiple network interfaces (if
available).
Note:
* To enable Direct NFS Client, you must replace the standard Oracle Disk Manager (ODM) library
with one that supports Direct NFS Client.
Incorrect:
Not A: Direct NFS Client is capable of performing concurrent
direct I/O, which bypasses any operating system level caches and eliminates any
operating system write-ordering locks
Not B:
* To use Direct NFS Client, the NFS file systems must first be mounted and available
over regular NFS mounts.
* Oracle Direct NFS (dNFS) is an optimized NFS (Network File System) client that provides faster
and more scalable access to NFS storage located on NAS storage devices (accessible over
TCP/IP).
Not D: Direct NFS is provided as part of the database kernel, and is thus available on all
supported database platforms – even those that don’t support NFS natively, like Windows.
Note:
* Oracle Direct NFS (dNFS) is an optimized NFS (Network File System) client that provides faster
and more scalable access to NFS storage located on NAS storage devices (accessible over
TCP/IP). Direct NFS is built directly into the database kernel – just like ASM which is mainly used
when using DAS or SAN storage.
* Oracle Direct NFS (dNFS) is an internal I/O layer that provides faster access to large NFS files
than traditional NFS clients.
C&E
C E
" . 46293) ((marker) . -1394) 47687 nil ("Block corruptions can be divided Into Interblock corruption and intrablock corruption. In intrablock
corruption. th« corruption occurs within the block itself and can be either physical or logical
corruption. In interblock corruption, the corruption occurs between blocks and can only be logical
corruption.
(key word) * The VALIDATE command checks for intrablock corruptions only. Only DBVERIFY
and the ANALYZE statement detect Interblock corruption.
VALIDATE Command Output ••> List of Control File and SPFILE.
File TYPE >»» SPFILE or Control File.
Status >»» OK if no corruption, or FAILED If block corruption is found.
Blocks Failing »»» The number of blocks that fail the corruption check. These
blocks are newly corrupt.
Blocks Examined »»» Total number of blocks in the file.
Oracle’ Database Backup and Recovery User’s Guide
12c Release 1 (12.1) – 16 Validating Database Files and Backups

A and C are correct-
http://docs.oracle.com/database/121/RCMRF/rcmsynta2025.htm#RCMRF90393
Block corruptions can be divided into interblock corruption and intrablock corruption. In intrablock corruption, the corruption occurs within the block itself and can be either physical or logical corruption. In interblock corruption, the corruption occurs between blocks and can only be logical corruption. The VALIDATE command checks for intrablock corruptions only.
*
Block corruptions can be divided into interblock corruption and intrablock corruption. In intrablock corruption, the corruption occurs within the block itself and can be either physical or logical corruption. In interblock corruption, the corruption occurs between blocks and can only be logical corruption. The VALIDATE command checks for intrablock corruptions only.
*
VALIDATE Command Output:
List of Control File and SPFILE
===============================
File Type Status Blocks Failing Blocks Examined
———— —— ————– —————
SPFILE OK 0 2
Control File OK 0 506
Finished validate at 26-FEB-13
validateObject
This subclause specifies database files for validation. Refer to validateObject::= for syntax.
SPFILE Validates the server parameter file currently used by the database. RMAN cannot validates other copies of the server parameter file, and cannot validate the server parameter file when the instance was started with an initialization parameter file.
см. доку: http://docs.oracle.com/database/121/RCMRF/rcmsynta2025.htm#RCMRF90393
A C
" . 45873) ((marker) . -2404) 48277 nil ("
Explanation:
Oracle 11g/12c makes further use of SQL tuning sets with the SQL Performance
Analyzer, which compares the performance of the statements in a tuning set before and after a
database change. The database change can be as major or minor as you like, such as:
* (E) Database, operating system, or hardware upgrades.
* (A,C) Database, operating system, or hardware configuration changes.
* Database initialization parameter changes.
* Schema changes, such as adding indexes or materialized views.
* Refreshing optimizer statistics.
* Creating or changing SQL profiles.
A,C and E true
A, C, E indeed
A C E
A C & E
Reference
https://docs.oracle.com/cd/B28359_01/server.111/e12159/spa.htm
ACE" . 45553) ((marker) . -697) 46250 nil ("
Explanation:
– You can now move On line Datafile without hove to stop Monoged Recovery and
manually copy and rename Files. This can even be used to move Datafiles from or to ASM.
– New in Oracle Database 12c: FROM METAUNK. Physical Standby Database is in Active Data
Guard Mode (opened READ ONLY and Managed Recovery is running):
It is now possible to online move a Datafile while Managed Recovery is running, ie. the Physical
Standby Database is in Active Data Guard Mode. You con use this Command to move the Datafile
– A flashback operation does not relocate a moved data file to its previous location. If you move a
data file online from one location to another and later flash back the database to a point in time
before the move, then the Data file remains in the new location, but the contents of the Data file
ore changed to the contents at the time specified in the flashback. Oracle0 Database
Administrator’s Guide 12c Release 1 (12.1)
A C E F
ACDF
ACDF
It is now possible to online move a Datafile while Managed Recovery is running
" . 45154) ((marker) . -1044) 46198 nil ("
Explanation:
D: The database internally uses standard file system interfaces to create and delete files as
needed for the following database structures:
Tablespaces
Redo log files
Control files
Archived logs
Block change tracking files
Flashback logs
RMAN backups
Note:
* Using Oracle-managed files simplifies the administration of an Oracle Database. Oraclemanaged files eliminate the need for you, the DBA, to directly manage the operating system files
that make up an Oracle Database. With Oracle-managed files, you specify file system directories
in which the database automatically creates, names, and manages files at the database object
level. For example, you need only specify that you want to create a tablespace; you do not need to
specify the name and path of the tablespace’s datafile with the DATAFILE clause.
http://www.oracle-base.com/articles/9i/oracle-managed-files.php
http://docs.oracle.com/cd/B10500_01/server.920/a96521/omf.htm
What Are Oracle-Managed Files?
D, E
D E
DE" . 44723) ((marker) . -993) 45716 nil ("Explanation:
A: PGA itself is subdivided. The UGA (User Global Area) contains session state
information, including stuff like package-level variables, cursor state, etc. Note that, with shared
server, the UGA is in the SGA. It has to be, because shared server means that the session state
needs to be accessible to all server processes, as any one of them could be assigned a particular
session. However, with dedicated server (which likely what you’re using), the UGA is allocated in
the PGA.
C: The Location of a private SQL area depends on the type of connection established for a
session. If a session is connected through a dedicated server, private SQL areas are located in
the server process’ PGA. However, if a session is connected through a shared server, part of the
private SQL area is kept in the SGA.
Note:
* System global area (SGA)
The SGA is a group of shared memory structures, known as SGA components, that contain data
and control information for one Oracle Database instance. The SGA is shared by all server and
background processes. Examples of data stored in the SGA include cached data blocks and
shared SQL areas.
* Program global area (PGA)
A PGA is a memory region that contains data and control information for a server process. It is
nonshared memory created by Oracle Database when a server process is started. Access to the
PGA is exclusive to the server process. There is one PGA for each server process. Background
processes also allocate their own PGAs. The total memory used by all individual PGAs is known
as the total instance PGA memory, and the collection of individual PGAs is referred to as the total
instance PGA, or just instance PGA. You use database initialization parameters to set the size of
the instance PGA, not individual PGAs.
Oracle Database Concepts 12c
A, C
A C
A, C are correct" . 44197) ((marker) . -1832) 46029 nil ("
Explanation:
Asynchronous Global Index Maintenance for DROP and TRUNCATE PARTITION
This feature enables global index maintenance to be delayed and decoupled from a DROP and
TRUNCATE partition without making a global index unusable. Enhancements include faster
DROP and TRUNCATE partition operations and the ability to delay index maintenance to off-peak
time.
Oracle Database VLDB and Partitioning Guide 12c
3 Responses to “Which two partitioned table maintenance operations support asynchronous Global Index Maintenance in Oracle database 12c?”
CE
C E
C & E
reference
https://docs.oracle.com/database/121/VLDBG/GUID-087B87A6-959A-40C6-82AF-36E401FD089B.htm#VLDBG14107" . 43836) ((marker) . -669) 44505 nil ("
Explanation:
Incorrect:
Not E, Not F When Heat Map is enabled, all accesses are tracked by the in-memory activity
tracking module. Objects in the SYSTEM and SYSAUX tablespaces are not tracked.
* To implement your ILM strategy, you can use Heat Map in Oracle Database to track data access
and modification.
Heat Map provides data access tracking at the segment-level and data modification tracking at the
segment and row level.
* To implement your ILM strategy, you can use Heat Map in Oracle Database to track data access
and modification. You can also use Automatic Data Optimization (ADO) to automate the
compression and movement of data between different tiers of storage within the database.
Automatic Data Optimization with Oracle Database 12c
with Oracle Database 12c
ABD
ABD" . 43524) ((marker) . -782) 44306 nil ("
Explanation:
The most of the rows in SUBSCRIBE_LOG table are accessed once a week.

D
D
D is correct
It is assumed that this utility is no longer to 12c
D" . 42954) ((marker) . -155) 43109 nil ("
Explanation:
You can design your applications to automatically grant a role to the user who is
trying to log in, provided the user meets criteria that you specify. To do so, you create a secure
application role, which is a role that is associated with a PL/SQL procedure (or PL/SQL package
that contains multiple procedures). The procedure validates the user: if the user fails the
validation, then the user cannot log in. If the user passes the validation, then the procedure grants
the user a role so that he or she can use the application. The user has this role only as long as he
or she is logged in to the application. When the user logs out, the role is revoked.
Incorrect:
Not B: REMOTE_OS_AUTHENT specifies whether remote clients will be authenticated with the
value of the OS_AUTHENT_PREFIX parameter.
Not C, not E: SEC_MAX_FAILED_LOGIN_ATTEMPTS specifies the number of authentication
attempts that can be made by a client on a connection to the server process. After the specified
number of failure attempts, the connection will be automatically dropped by the server process.
Not D: REMOTE_LOGIN_PASSWORDFILE specifies whether Oracle checks for a password file.
Values:
shared
One or more databases can use the password file. The password file can contain SYS as well as
non-SYS users.
exclusive
The password file can be used by only one database. The password file can contain SYS as well
as non-SYS users.
none
Oracle ignores any password file. Therefore, privileged users must be authenticated by the
operating system.
Note:
The REMOTE_OS_AUTHENT parameter is deprecated. It is retained for backward compatibility
only.
C
C
C is only correct for condition 1. What about the other conditions?
The Answer about using a profile and all the necessary limit is missing.
C" . 42353) ((marker) . -1782) 44135 nil ("
Explanation:
A: ASM_POWER_LIMIT specifies the maximum power on an Automatic Storage
Management instance for disk rebalancing. The higher the limit, the faster rebalancing will
complete. Lower values will take longer, but consume fewer processing and I/O resources.
D:
* Normally a separate process is fired up to do that rebalance. This will take a certain amount of
time. If you want it to happen faster, fire up more processes. You tell ASM it can add more
processes by increasing the rebalance power.
* ASMB
ASM Background Process
Communicates with the ASM instance, managing storage and providing statistics
Incorrect:
Not B: A higher, not a lower, value of DISK_REPAIR_TIME would be helpful here.
Not E: If you implement database writer I/O slaves by setting the DBWR_IO_SLAVES parameter,
you configure a single (master) DBWR process that has slave processes that are subservient to it.
In addition, I/O slaves can be used to “simulate” asynchronous I/O on platforms that do not
support asynchronous I/O or implement it inefficiently. Database I/O slaves provide non-blocking,
asynchronous requests to simulate asynchronous I/O.
guys, it’s really strange to see this question and looking at
http://education.oracle.com/pls/web_prod-plq-dad/db_pages.getpage?page_id=303&p_certName=SQ1Z0_053
where it reads clearly:
2. Which option speeds up the disk rebalancing in an Automatic Storage Management (ASM) disk group by increasing the degree of parallelism?
A Increasing ASM_POWER_LIMIT
B Increasing the number of DBWR processes
C Increasing the number of ASMB processes
D Increasing the number of DBWR_IO_SLAVES
answer A
A C
A D" . 41410) ((marker) . -1631) 43041 nil ("
" . -40602) ((marker . 15876) . -1) nil ("Explanation:
* You can create a password file using the password file creation utility, ORAPWD.
* Adding Users to a Password File
When you grant SYSDBA or SYSOPER privileges to a user, that user’s name and privilege
information are added to the password file. If the server does not have an EXCLUSIVE password
file (that is, if the initialization parameter REMOTE_LOGIN_PASSWORDFILE is NONE or
SHARED, or the password file is missing), Oracle Database issues an error if you attempt to grant
these privileges.
A user’s name remains in the password file only as long as that user has at least one of these two
privileges. If you revoke both of these privileges, Oracle Database removes the user from the
password file.
* The syntax of the ORAPWD command is as follows:
ORAPWD FILE=filename [ENTRIES=numusers]
[FORCE={Y|N}] [IGNORECASE={Y|N}] [NOSYSDBA={Y|N}]
* IGNORECASE
If this argument is set to y, passwords are case-insensitive. That is, case is ignored when
comparing the password that the user supplies during login with the password in the password file.
A, D
A D
" . 40603) ((marker) . -1071) 41674 nil ("A
A
A
Reference : https://docs.oracle.com/database/121/ADMIN/memory.htm#ADMIN13395
A" . 39888) ((marker) . -84) 39972 nil ("
" . -39448) ((marker . 15876) . -1) nil ("E" . -39449) ((marker . 15876) . -1) nil ("x" . -39450) ((marker . 15876) . -1) nil ("p" . -39451) ((marker . 15876) . -1) nil ("l" . -39452) ((marker . 15876) . -1) nil ("a" . -39453) ((marker . 15876) . -1) nil ("n" . -39454) ((marker . 15876) . -1) nil ("a" . -39455) ((marker . 15876) . -1) nil ("t" . -39456) ((marker . 15876) . -1) nil ("i" . -39457) ((marker . 15876) . -1) nil ("o" . -39458) ((marker . 15876) . -1) nil ("n" . -39459) ((marker . 15876) . -1) nil (":" . -39460) ((marker . 15876) . -1) nil ("
" . -39461) ((marker . 5488) . -1) ((marker . 15876) . -1) nil ("AD: The value for the disk group COMPATIBLE.ASM attribute determines the
minimum software version for an Oracle ASM instance that can use the disk group. This setting
also affects the format of the data structures for the Oracle ASM metadata on the disk.
B: The value for the disk group COMPATIBLE.RDBMS attribute determines the minimum
COMPATIBLE database initialization parameter setting for any database instance that is allowed
to use the disk group. Before advancing the COMPATIBLE.RDBMS attribute, ensure that the
values for the COMPATIBLE initialization parameter for all of the databases that access the disk
group are set to at least the value of the new setting for COMPATIBLE.RDBMS.
For example, if the COMPATIBLE initialization parameters of the databases are set to either 11.1
or 11.2, then COMPATIBLE.RDBMS can be set to any value between 10.1 and 11.1 inclusively.
Not E:
/The value for the disk group COMPATIBLE.ADVM attribute determines whether the disk group
can contain Oracle ASM volumes. The value must be set to 11.2 or higher. Before setting this
attribute, the COMPATIBLE.ASM value must be 11.2 or higher. Also, the Oracle ADVM volume
drivers must be loaded in the supported environment.
/ You can create an Oracle ASM Dynamic Volume Manager (Oracle ADVM) volume in a disk
group. The volume device associated with the dynamic volume can then be used to host an
Oracle ACFS file system.
The compatibility parameters COMPATIBLE.ASM and COMPATIBLE.ADVM must be set to 11.2
or higher for the disk group.
Note:
* The disk group attributes that determine compatibility are COMPATIBLE.ASM,
COMPATIBLE.RDBMS. and COMPATIBLE.ADVM. The COMPATIBLE.ASM and
COMPATIBLE.RDBMS attribute settings determine the minimum Oracle Database software
version numbers that a system can use for Oracle ASM and the database instance types
respectively. For example, if the Oracle ASM compatibility setting is 11.2, and RDBMS
compatibility is set to 11.1, then the Oracle ASM software version must be at least 11.2, and the
Oracle Database client software version must be at least 11.1. The COMPATIBLE.ADVM attribute
determines whether the Oracle ASM Dynamic Volume Manager feature can create an volume in a
disk group.
A B D
A B D
Reference : https://docs.oracle.com/cd/E11882_01/server.112/e18951/asmdiskgrps.htm#OSTMG10045
Here is a superb Weblog You may Discover Exciting that we Encourage You
always a big fan of linking to bloggers that I like but really don’t get a great deal of link enjoy from
just beneath, are several completely not associated sites to ours, on the other hand, they may be surely worth going over
we came across a cool web page which you may possibly delight in. Take a search in the event you want
please pay a visit to the sites we comply with, like this one particular, because it represents our picks from the web
the time to read or go to the content or sites we’ve linked to below the
one of our guests lately recommended the following website
" . 39462) ((marker) . -2976) 42438 nil ("
Explanation:
Note:
* BY SESSION
In earlier releases, BY SESSION caused the database to write a single record for all SQL
statements or operations of the same type executed on the same schema objects in the same
session. Beginning with this release (11g) of Oracle Database, both BY SESSION and BY
ACCESS cause Oracle Database to write one audit record for each audited statement and
operation.
* BY ACCESS
Specify BY ACCESS if you want Oracle Database to write one record for each audited statement
and operation.
Note:
If you specify either a SQL statement shortcut or a system privilege that audits a data definition
language (DDL) statement, then the database always audits by access. In all other cases, the
database honors the BY SESSION or BY ACCESS specification.
* For each audited operation, Oracle Database produces an audit record containing this
information:
/ The user performing the operation
/ The type of operation
/ The object involved in the operation
/ The date and time of the operation
Oracle Database SQL Language Reference 12c
A indeed
http://docs.oracle.com/database/121/SQLRF/statements_4007.htm#SQLRF01107
A
D
A. By default AUDIT_TRIAL=DB. Database was not restarted does the extended did not take any affect.
This is alternative D for sure. It explicitly says that the instance was restarted. It then records SQL text and bind variables.
https://docs.oracle.com/cd/B19306_01/server.102/b14237/initparams016.htm#REFRN10006
I think the same. It says that te instance was restarted" . 38589) ((marker) . -1506) 40095 nil ("
" . -37416) ((marker . 15876) . -1) nil ("Explanation:
DBMS_FGA.add_policy
* The DBMS_FGA package provides fine-grained security functions.
* ADD_POLICY Procedure
This procedure creates an audit policy using the supplied predicate as the audit condition.
Incorrect:
Not C: object_schema
The schema of the object to be audited. (If NULL, the current log-on user schema is assumed.)
A, B
Default statement type is SELECT (if not provided)
A B
A/D
https://oracle-base.com/articles/10g/auditing-10gr2
Not B: Each audit policy is applied to the query individually. However, at most one audit record may be generated for each policy, no matter how many rows being returned satisfy that policy’s audit_condition. In other words, whenever any number of rows being returned satisfy an audit condition defined on the table, a single audit record will be generated for each such policy." . 37417) ((marker) . -833) 38250 nil ("
" . -36865) ((marker . 15876) . -1) nil ("Explanation:
The listener is used when the connection is established. The immediate impact of
stopping the listener will be that no new session can be established from a remote host. Existing
sessions are not compromised.
B
B
Genuinely no matter if someone doesn’t be aware of afterward its up to other people that they will help, so here it occurs.
-" . 36866) ((marker) . -351) 37217 nil ("
" . -36369) ((marker . 15876) . -1) nil ("Explanation:
Note:
* DBMS_REDACT.FULL completely redacts the column data.
* DBMS_REDACT.NONE applies no redaction on the column data. Use this function for
development testing purposes. LOB columns are not supported.
* The DBMS_REDACT package provides an interface to Oracle Data Redaction, which enables
you to mask (redact) data that is returned from queries issued by low-privileged users or an
application.
* If you create a view chain (that is, a view based on another view), then the Data Redaction policy
also applies throughout this view chain. The policies remain in effect all of the way up through this
view chain, but if another policy is created for one of these views, then for the columns affected in
the subsequent views, this new policy takes precedence.
AC
A C" . 36370) ((marker) . -778) 37148 nil ("
" . -35668) ((marker . 15876) . -1) nil ("Explanation:
A:
1. Get the list of all datafiles.
Note: RMAN Backup of ASM Storage
There is often a need to move the files from the file system to the ASM storage and vice versa.
This may come in handy when one of the file systems is corrupted by some means and then the
file may need to be moved to the other file system.
D: Migrating a Database into ASM
* To take advantage of Automatic Storage Management with an existing database you must
migrate that database into ASM. This migration is performed using Recovery Manager (RMAN)
even if you are not using RMAN for your primary backup and recovery strategy.
* Example:
Back up your database files as copies to the ASM disk group.
BACKUP AS COPY INCREMENTAL LEVEL 0 DATABASE
FORMAT ‘+DISK’ TAG ‘ORA_ASM_MIGRATION’;
Migrating Databases To and From ASM with Recovery Manager
D, E
http://docs.oracle.com/database/121/OSTMG/asmfiles.htm#OSTMG94229
http://docs.oracle.com/database/121/OSTMG/toc.htm
D E
It is A & D:
A because:
One use of CONVERT is to transport a tablespace into a database stored in Oracle Automatic Storage Management (Oracle ASM). Native operating system commands such as Linux cp and Windows COPY cannot read from or write to Oracle ASM disk groups.
" . 35669) ((marker) . -1218) 36887 nil ("
" . -35291) ((marker . 15876) . -1) nil ("Explanation:
B: Job priorities are used only to prioritize among jobs in the same class.
Note: Group jobs for prioritization
Within the same job class, you can assign priority values of 1-5 to individual jobs
so that if two jobs in the class are scheduled to start at the same time, the one with
the higher priority takes precedence. This ensures that you do not have a less
important job preventing the timely completion of a more important one.
C: Set resource allocation for member jobs
Job classes provide the link between the Database Resource Manager and the
Scheduler, because each job class can specify a resource consumer group as an
attribute. Member jobs then belong to the specified consumer group and are
assigned resources according to settings in the current resource plan.
B, C
B C" . 35292) ((marker) . -797) 36089 nil ("
" . -34543) ((marker . 15876) . -1) nil ("Explanation:
B (not C): You can validate that all database files and archived redo logs can be
backed up by running a command as follows:
RMAN> BACKUP VALIDATE DATABASE ARCHIVELOG ALL;
This form of the command would check for physical corruption. To check for logical corruption,
RMAN> BACKUP VALIDATE CHECK LOGICAL DATABASE ARCHIVELOG ALL;
D: You can use the VALIDATE keyword of the BACKUP command to do the following:
Check datafiles for physical and logical corruption
Confirm that all database files exist and are in the correct locations.
Note:
You can use the VALIDATE option of the BACKUP command to verify that database files exist
and are in the correct locations (D), and have no physical or logical corruptions that would prevent
RMAN from creating backups of them. When performing a BACKUP…VALIDATE, RMAN reads
the files to be backed up in their entirety, as it would during a real backup. It does not, however,
actually produce any backup sets or image copies (Not A, not E).
B, D
To verify logical errors following should be used:
BACKUP VALIDATE
CHECK LOGICAL
DATABASE
ARCHIVELOG ALL;
https://docs.oracle.com/database/121/BRADV/rcmvalid.htm#BRADV89562
You can use the BACKUP VALIDATE command to do the following:
Check data files for physical and logical block corruption
Confirm that all database files exist and are in the correct locations
I’d rather say BCD.
http://docs.oracle.com/cd/B19306_01/backup.102/b14192/bkup005.htm
You can use the VALIDATE option of the BACKUP command to verify that database files exist and are in the correct locations, and have no physical or logical corruptions that would prevent RMAN from creating backups of them. When performing a BACKUP… VALIDATE, RMAN reads the files to be backed up in their entirety, as it would during a real backup. It does not, however, actually produce any backup sets or image copies.
Sorry, you’re right.
B D
" . 34544) ((marker) . -1890) 36434 nil ("
" . -34013) ((marker . 15876) . -1) nil ("
" . -34014) ((marker . 15876) . -1) nil ("Explanation:
A: The APPEND keyword tells SQL*Loader to preserve any preexisting data in the
table. Other options allow you to delete preexisting data, or to fail with an error if the table is not
empty to begin with.
B (not D):
Note:
* SQL*Loader-00210: first data file is empty, cannot process the FIELD NAMES record
Cause: The data file listed in the next message was empty. Therefore, the FIELD NAMES FIRST
FILE directive could not be processed.
Action: Check the listed data file and fix it. Then retry the operation
E:
* A comma-separated values (CSV) (also sometimes called character-separated values, because
the separator character does not have to be a comma) file stores tabular data (numbers and text)
in plain-text form. Plain text means that the file is a sequence of characters, with no data that has
to be interpreted instead, as binary numbers. A CSV file consists of any number of records,
separated by line breaks of some kind; each record consists of fields, separated by some other
character or string, most commonly a literal comma or tab. Usually, all records have an identical
sequence of fields.
* Fields with embedded commas must be quoted.
Example:
1997,Ford,E350,”Super, luxurious truck”
Note:
* SQL*Loader is a bulk loader utility used for moving data from external files into the Oracle
database.
B, E
ABE
BDE
“A” is wrong, sqlldr can’t create table
“C” is wrong, terminators can be pass by default in CSV format
B E" . 34015) ((marker) . -1445) 35460 nil ("
Explanation:
Manually Sized SGA Components that Use SGA_TARGET Space
SGA Component, Initialization Parameter
/ The log buffer
LOG_BUFFER
/ The keep and recycle buffer caches
DB_KEEP_CACHE_SIZE
DB_RECYCLE_CACHE_SIZE
/ Nonstandard block size buffer caches
DB_nK_CACHE_SIZE
Note:
* In addition to setting SGA_TARGET to a nonzero value, you must set to zero all initialization
parameters listed in the table below to enable full automatic tuning of the automatically sized SGA
components.
* Table, Automatically Sized SGA Components and Corresponding Parameters

The manually tuned ASMM initialization parameters are DB_KEEP_CACHE_
SIZE, DB_RECYCLE_CACHE_SIZE, DB_nK_CACHE_SIZE, and LOG_BUFFER.
A, E, F
A E F
Sort_area_size is in the pga. Does this count in asmm? Should the answer be abde?
Sorry I meant abef?
AEF" . 33347) ((marker) . -811) 34158 nil ("
" . -32991) ((marker . 15876) . -1) nil ("Explanation:
* Smart Flash Cache concept is not new in Oracle 12C – DB Smart Flash Cache in
Oracle 11g.
In this release Oracle has made changes related to both initialization parameters used by DB
Smart Flash cache. Now you can define many files|devices and its sizes for “Database Smart
Flash Cache” area. In previous releases only one file|device could be defined.
DB_FLASH_CACHE_FILE = /dev/sda, /dev/sdb, /dev/sdc
DB_FLASH_CACHE_SIZE = 32G, 32G, 64G
So above settings defines 3 devices which will be in use by “DB Smart Flash Cache”
/dev/sda – size 32G
/dev/sdb – size 32G
/dev/sdc – size 64G
New view V$FLASHFILESTAT – it’s used to determine the cumulative latency and read counts of
each file|device and compute the average latency
B." . 32992) ((marker) . -740) 33732 nil ("
" . -32466) ((marker . 15876) . -1) nil ("Explanation:
RMAN tablespace point-in-time recovery (TSPITR).
Recovery Manager (RMAN) TSPITR enables quick recovery of one or more tablespaces in a
database to an earlier time without affecting the rest of the tablespaces and objects in the
database.
Fully Automated (the default)
In this mode, RMAN manages the entire TSPITR process including the auxiliary instance. You
specify the tablespaces of the recovery set, an auxiliary destination, the target time, and you allow
RMAN to manage all other aspects of TSPITR.
The default mode is recommended unless you specifically need more control over the location of
recovery set files after TSPITR, auxiliary set files during TSPITR, channel settings and parameters
or some other aspect of your auxiliary instance.
C
A
https://docs.oracle.com/database/121/BRADV/rcmflash.htm#BRADV81511
E, since OCP user have the privilege
A – error, tested.
C
C
C
“Automated” Tablespace point in time recovery is a new functionality from 12C, not ?
" . 32467) ((marker) . -980) 33447 nil ("Explanation:

A: Variable size extents enable support for larger ASM datafiles, reduce SGA
memory requirements for very large databases (A), and improve performance for file create and
open operations.
C: You don’t have to worry about the sizes; the ASM instance automatically allocates the
appropriate extent size.
Note:
* The contents of ASM files are stored in a disk group as a set, or collection, of data extents that
are stored on individual disks within disk groups. Each extent resides on an individual disk.
Extents consist of one or more allocation units (AU). To accommodate increasingly larger files,
ASM uses variable size extents.
* The size of the extent map that defines a file can be smaller by a factor of 8 and 64 depending
on the file size. The initial extent size is equal to the allocation unit size and it increases by a factor
of 8 and 64 at predefined thresholds. This feature is automatic for newly created and resized
datafiles when the disk group compatibility attributes are set to Oracle Release 11 or higher.
AC
AC
A-C
ASM does not eliminate any existing database functionality. Existing databases are able to
operate as they always have. New files may be created as ASM files, whereas existing ones
are administered in the old way or can be migrated to ASM.
The diagram illustrates the relationships between an Oracle database data file and the ASM
storage components. The crow’s foot notation represents a one-to-many relationship. An
Oracle Database data file has a one-to-one relationship with either a file stored on the
operating system in a file system or an ASM file.
An Oracle ASM disk group is a collection of one or more Oracle ASM disks managed as a
logical unit. The data structures in a disk group are self-contained using some of the space for
metadata needs. Oracle ASM disks are the storage devices provisioned to an Oracle ASM
disk group and can be physical disk or partitions,
a Logical Unit Number (LUN) from a storage
array, a logical volume (LV), or a network-attached file. Each ASM disk is divided into many
ASM allocation units, the smallest contiguous amount of disk space that ASM allocates. When
you create an ASM disk group, you can set the ASM allocation unit size to 1, 2, 4, 8, 16, 32,
or 64 MB depending on the disk group compatibility level. One or more ASM allocation units
forms an ASM extent. An Oracle ASM extent is the raw storage used to hold the contents of
an Oracle ASM file. An Oracle ASM file consists
of one or more file extents. Variable extent
sizes of 1*AU size, 4*AU size, and 16*AU size are used for supporting very large ASM files" . 31641) ((marker) . -2613) 34254 nil ("
" . -31150) ((marker . 15876) . -1) nil ("Explanation:
* optimizer_dynamic_sampling
OPTIMIZER_DYNAMIC_SAMPLING controls both when the database gathers dynamic statistics,
and the size of the sample that the optimizer uses to gather the statistics.
Range of values0 to 11
C
i think B
B
A dynamic plan hash /nested loop
A
According to Schebge_u_Zama and amsunhasav. I think that answer A this correct.
http://oracleinaction.com/12c-optimizer_dynamic_sampling-11/
B
" . 31151) ((marker) . -421) 31572 nil ("
" . -30484) ((marker . 15876) . -1) nil ("Explanation:
Keyword: shows the difference.
* Full ADDM analysis across two AWR snapshot periods
Detects causes, measure effects, then correlates them
Causes: workload changes, configuration changes
Effects: regressed SQL, reach resource limits (CPU, I/O, memory, interconnect)
Makes actionable recommendations along with quantified impact
* Identify what changed
/ Configuration changes, workload changes
* Performance degradation of the database occurs when your database was performing optimally
in the past, such as 6 months ago, but has gradually degraded to a point where it becomes
noticeable to the users. The Automatic Workload Repository (AWR) Compare Periods report
enables you to compare database performance between two periods of time.
While an AWR report shows AWR data between two snapshots (or two points in time), the AWR
Compare Periods report shows the difference (ABE) between two periods (or two AWR reports
with a total of four snapshots). Using the AWR Compare Periods report helps you to identify
detailed performance attributes and configuration settings that differ between two time periods.
Resolving Performance Degradation Over Time
ABD
ABD" . 30485) ((marker) . -1170) 31655 nil (29686 . 29687) nil ("
" . -29686) ((marker . 5488) . -1) ((marker . 15876) . -1) nil ("creating indexes.
The new TRANSFORM option introduced in data pumps import provides the flexibility to turn off
the redo generation for the objects during the course of import. The Master Table is used to track
the detailed progress information of a Data Pump job.
The Master Table is created in the schema of the current user running the Pump Dump export or
import, and it keeps tracks of lots of detailed information.
the answer is “B”
“DISABLE_ARCHIVE_LOGGING:[Y | N]
If set to Y, then the logging attributes for the specified object types (TABLE and/or INDEX) are disabled before the data is imported. If set to N (the default), then archive logging is not disabled during import. After the data has been loaded, the logging attributes for the objects are restored to their original settings. If no object type is specified, then the DISABLE_ARCHIVE_LOGGING behavior is applied to both TABLE and INDEX object types. This transform works for both file mode imports and network mode imports. It does not apply to transportable tablespace imports.”
http://docs.oracle.com/database/121/SUTIL/dp_import.htm#SUTIL939
Correct Answer is “C”!!!
“The new TRANSFORM option, DISABLE_ARCHIVE_LOGGING, to the impdp command line causes Oracle Data Pump to disable redo logging when loading data into tables and when creating indexes. It also adds the same option as part of the PL/SQL DBMS_DATAPUMP package. With redo logging disabled, the disk space required for redo logs during an Oracle Data Pump import is smaller. However, to ensure recovery from media failure, the DBA should do an RMAN backup after the import completes.
Even with this parameter specified, there is still redo logging for other operations of Oracle Data Pump. This includes all CREATE and ALTER statements, except CREATE INDEX, and all operations against the master table used by Oracle Data Pump during the import.”
http://docs.oracle.com/database/121/NEWFT/chapter12101.htm#NEWFT253
D
Without “Only”, answer C is also correct.
But from docu
This includes all CREATE and ALTER statements, except CREATE INDEX, and all operations against the master table used by Oracle Data Pump during the import.
http://docs.oracle.com/database/121/NEWFT/chapter12101.htm#NEWFT253
Answer D for me is correct
C
D
C
C is correct
D incorrect!!!
A small amount of logging will still happen when the objects are created
in the database. If the database is running in FORCE LOGGING mode, setting this parameter
has no effect.
Logging is disabled by using the TRANSFORM parameter. The syntax is
TRANSFORM=DISABLE_ARCHIVE_LOGGING:Y|N[:TABLE|INDEX]
You can choose to disable logging for tables, indexes, or both. If you specify Y:TABLE,
logging is disabled for table loads. If you specify Y:INDEX, logging is disabled only for index
creation. If you do not specify TABLE or INDEX along with Y, logging is disabled for both
tables and indexes.
B.
C" . 29687) ((marker) . -2888) 32575 nil ("
" . -28997) ((marker . 15876) . -1) nil ("Explanation:
You can use the SQL Performance Analyzer to analyze the SQL performance
impact of any type of system change. Examples of common system changes include:
•Database upgrades
•Configuration changes to the operating system, hardware, or database
•Database initialization parameter changes
•Schema changes, such as adding new indexes or materialized views
•Gathering optimizer statistics
•SQL tuning actions, such as creating SQL profiles
http://docs.oracle.com/cd/B28359_01/server.111/b28318/intro.htm#CNCPT961
D
A
D
D
" . 28998) ((marker) . -527) 29525 nil ("
" . -28553) ((marker . 15876) . -1) nil ("
" . -28554) ((marker . 15876) . -1) nil ("Explanation:
Schema objects are referenced with varying usage patterns; therefore, their cache
behavior may be quite different. Multiple buffer pools enable you to address these
differences. You can use a KEEP buffer pool to maintain objects in the buffer cache
and a RECYCLE buffer pool to prevent objects from consuming unnecessary space in the
cache. When an object is allocated to a cache, all blocks from that object are placed in
that cache. Oracle maintains a DEFAULT buffer pool for objects that have
not been assigned to one of the buffer pools.
C is not correct
B
A, because it is the easiest and fastest way
A
A
A
A" . 28555) ((marker) . -626) 29181 nil ("
" . -28047) ((marker . 15876) . -1) nil ("Explanation:
Step 1 (2). Seed column usage
Oracle must observe a representative workload, in order to determine the appropriate column
groups. Using the new procedure DBMS_STATS.SEED_COL_USAGE, you tell Oracle how long it
should observe the workload.
Step 2: (3) You don’t need to execute all of the queries in your work during this window. You can
simply run explain plan for some of your longer running queries to ensure column group
information is recorded for these queries.
Step 3. (1) Create the column groups
At this point you can get Oracle to automatically create the column groups for each of the tables
based on the usage information captured during the monitoring window. You simply have to call
the DBMS_STATS.CREATE_EXTENDED_STATS function for each table.This function requires
just two arguments, the schema name and the table name. From then on, statistics will be
maintained for each column group whenever statistics are gathered on the table.
Note:
* DBMS_STATS.REPORT_COL_USAGE reports column usage information and records all the
SQL operations the database has processed for a given object.
* The Oracle SQL optimizer has always been ignorant of the implied relationships between data
columns within the same table. While the optimizer has traditionally analyzed the distribution of
values within a column, he does not collect value-based relationships between columns.
* Creating extended statisticsHere are the steps to create extended statistics for related table
columns withdbms_stats.created_extended_stats:
1 – The first step is to create column histograms for the related columns.2 – Next, we run
dbms_stats.create_extended_stats to relate the columns together.
Unlike a traditional procedure that is invoked via an execute (“exec”) statement, Oracle extended
statistics are created via a select statement.
B
B
B
B" . 28048) ((marker) . -1843) 29891 nil (27461 . 27462) nil ("
" . -27461) ((marker . 15876) . -1) nil ("Explanation:
* A fundamental aspect of the workload repository is that it collects and persists
database performance data in a manner that enables historical performance analysis.
The mechanism for this is the AWR snapshot. On a periodic basis, AWR takes a
“snapshot” of the current statistic values stored in the database instance’s memory
and persists them to its tables residing in the SYSAUX tablespace.
* AWR is primarily designed to provide input to higherlevel components such as automatic tuning
algorithms and advisors, but can also provide a wealth of information for the manual tuning
process.
I think is CDE
AWR data is stored in the WRH$ and DBA_HIST tables in the SYSAUX tablespace, is owned by SYS.
ASH not AWR, Active sessions are sampled every second and are stored in a circular buffer in SGA.
I think B,C$D.
B. This data is both in memory and stored in the database.
C AWR collects, processes, and maintains performance statistics for problem detection and self-tuning purposes.
D. The statistics collected and processed by AWR include:time model statistics based on time usage for activities, displayed in the V$SYS_TIME_MODEL and V$SESS_TIME_MODEL views
I think B, C & D
B, C and D => congrat Sayed 72% !
B C D
B C D !!
BCD
" . 27462) ((marker) . -1245) 28707 nil ("
" . -26980) ((marker . 15876) . -1) nil ("Explanation:
The awrddrpt.sql report is the Automated Workload Repository Compare Period Report. The awrddrpt.sql script is located in the $ORACLE_HOME/rdbms/admin directory.
Incorrect:
Not A: Compare Period ADDM
Use this report to perform a high-level comparison of one workload replay to its capture or to another replay of the same capture. Only workload replays that contain at least 5 minutes of database time can be compared using this report.
B
AWR Compare Periods report shows the difference between two periods (or two AWR reports, which equates to four snapshots). Using the AWR Compare Periods report helps you to identify detailed performance attributes and configuration settings that differ between two time periods.
B
why not A? it is albo used to compare 2 periods in terms of performance
B" . 26981) ((marker) . -806) 27787 nil ("
" . -26630) ((marker . 15876) . -1) nil ("Explanation:
* In bind variable peeking (also known as bind peeking), the optimizer looks at the value in a bind variable when the database performs a hard parse of a statement. When a query uses literals, the optimizer can use the literal values to find the best plan. However, when a query uses bind variables, the optimizer must select the best plan without the presence of literals in the SQL text. This task can be extremely difficult. By peeking at bind values the optimizer can determine the selectivity of a WHERE clause condition as if literals had been used, thereby improving the plan.
C: Oracle 11g/12g uses Adaptive Cursor Sharing to solve this problem by allowing the server to
compare the effectiveness of execution plans between executions with different bind variable values. If it notices suboptimal plans, it allows certain bind variable values, or ranges of values, to use alternate execution plans for the same statement. This functionality requires no additional configuration.
ACE
A C E
ACS allows there to be different plans for the same cursor with bind variables, but limits this based upon the selectivity of those bind variables rather than having a different plan for every bind (as you would with literals).

what about B
SQL Plan Baselines are designed to work with Adaptive Cursor Sharing. Any valid enabled SQL Plan Baselines Plans can be used by Adaptive Cursor Sharing. This means if you have more than one enabled baseline for a given SQL statement ACS can use one or more of those baselines at the same time
ACE" . 26631) ((marker) . -1548) 28179 nil ("Explanation:
D: DB_FILE_MULTIBLOCK_READ_COUNT is one of the parameters you can use to minimize I/O during table scans. It specifies the maximum number of blocks read in one I/O operation during a sequential scan. The total number of I/Os needed to perform a full table scan depends on such factors as the size of the table, the multiblock read count, and whether parallel execution is being utilized for the operation.
ACD
Please check the answer, as C, D, E seems more likely. Oversize buffer cache can prefer full table sacn during CBO decision making. Buffer cache size is one of factor in decision making whether full table sacn would be used or not.
On the same time missing or stale histogram might be related to old stats of index & table, and accordingly to those old stats as well index scan couldn’t be considered in execution path. Only difference would be there that it would go through high db file sequential read but there is no reason it will not hit index with old stats.
A C D
ACD" . 26329) ((marker) . -998) 27327 nil ("
" . -25749) ((marker . 15876) . -1) nil ("Explanation:
utlrp.sql and utlprp.sql
The utlrp.sql and utlprp.sql scripts are provided by Oracle to recompile all invalid objects in the database. They are typically run after major database changes such as upgrades or patches. They are located in the $ORACLE_HOME/rdbms/admin directory and provide a wrapper on the UTL_RECOMP package. The utlrp.sql script simply calls the utlprp.sql script with a command line parameter of “0”. The utlprp.sql accepts a single integer parameter that indicates the level of parallelism as follows.
0 – The level of parallelism is derived based on the CPU_COUNT parameter.
1 – The recompilation is run serially, one object at a time.
N – The recompilation is run in parallel with “N” number of threads.
Both scripts must be run as the SYS user, or another user with SYSDBA, to work correctly.
Recompiling Invalid Schema Objects
C&E.
Note: Selecting Recompile invalid objects at the end of upgrade is equivalent to running the utlrp.sql script, located in the ORACLE_HOME/rdbms/admin directory, which is used to recompile stored PL/SQL and Java code.
C E
CE
CE
-" . 25750) ((marker) . -1095) 26845 nil ("
" . -25266) ((marker . 15876) . -1) nil ("Explanation:
C: To use Oracle ASM or Oracle Restart, you must first install Oracle Grid Infrastructure for a standalone server before you install and create the database. Otherwise, you must manually register the database with Oracle Restart.
Desupport of Block and Raw Devices With the release of Oracle Database 11g release 2 (11.2) and Oracle RAC 11g release 2 (11.2), using Database Configuration Assistant or the installer to store Oracle Clusterware or Oracle Database files directly on block or raw devices is not supported.
If you intend to upgrade an existing Oracle RAC database, or an Oracle RAC database with Oracle ASM instances, then you can use an existing raw or block device partition, and perform a rolling upgrade of your existing installation. Performing a new installation using block or raw devices is not allowed.
Oracle Grid Infrastructure for a Standalone Server, Oracle Database, Installation Guide, 12c
CD
is it not C & E
3.4 Desupport of Block and Raw Devices With the release of Oracle Database and Oracle RAC 11g release 2 (11.2), using Database Configuration Assistant or the installer to store Oracle Clusterware or Oracle Database files on block or raw devices is not supported.
If you intend to upgrade an existing Or
acle RAC database, or an Oracle RAC database with Oracle ASM instances, then you can use an existing raw or block device partition, and perform a rolling upgrade of your existing installation. Performing a new installation using block or raw devices is not allowed.
So I think E is not correct.
578455.1 Announcement of De-Support of using RAW devices in Oracle Database Version 12.1
754305.1 Announcement on using Raw devices with release 11.2
Block or raw devices couldnt be used directly but they can be used through ASM, so Grid infra could help in achieveing that.
A C
A,C
why A is correct?
I think correct CD
AC
I didn’t find anything supports for A
D If you have an Oracle ASM installation from a prior release installed on your server, or in an existing Oracle Grid Infrastructure installation, you can use Oracle Automatic Storage Management Configuration Assistant (Oracle ASMCA) to upgrade the existing Oracle ASM instance to 11g Release 2 (11.2), and subsequently configure disk groups, Oracle ASM volumes and Oracle ASM file systems.
A ??? What is mean “Effectively implements role separation” ?
I think is CD
A, C:
https://docs.oracle.com/database/121/CWSOL/usrgrps.htm#CWSOL763
" . 25267) ((marker) . -2445) 27712 nil ("
" . -24810) ((marker . 15876) . -1) nil ("Explanation:
Example:
SQL> startup force 
ORA-00824: cannot set SGA_TARGET or MEMORY_TARGET due to existing internal settings 
ORA-00848: STATISTICS_LEVEL cannot be set to BASIC with SGA_TARGET or
MEMORY_TARGET
B
B
B
STATISTICS_LEVEL specifies the level of collection for database and operating system statistics. The Oracle Database collects these statistics for a variety of purposes, including making self-management decisions.
The default setting of TYPICAL ensures collection of all major statistics required for database self-management functionality and provides best overall performance. The default value should be adequate for most environments.
When the STATISTICS_LEVEL parameter is set to ALL, additional statistics are added to the set of statistics collected with the TYPICAL setting. The additional statistics are timed operating system statistics and plan execution statistics.
Setting the STATISTICS_LEVEL parameter to BASIC disables the collection of many of the important statistics required by Oracle Database features and functionality,
Reference,https://docs.oracle.com/database/121/REFRN/GUID-16B23F95-8644-407A-A6C8-E85CADFA61FF.htm#REFRN10214
B
B" . 24811) ((marker . 15876) . -1172) ((marker) . -1172) nil ("Explanation:
* Oracle Database provides a mechanism to make table structure modifications without significantly affecting the availability of the table. The mechanism is called online table redefinition. Redefining tables online provides a substantial increase in availability compared to traditional methods of redefining tables.
* To redefine a table online:
Choose the redefinition method: by key or by rowid
* By key—Select a primary key or pseudo-primary key to use for the redefinition. Pseudo-primary keys are unique keys with all component columns having NOT NULL constraints. For this method, the versions of the tables before and after redefinition should have the same primary key columns.
This is the preferred and default method of redefinition.
* By rowid—Use this method if no key is available. In this method, a hidden column named M_ROW$$ is added to the post-redefined version of the table. It is recommended that this column
be dropped or marked as unused after the redefinition is complete. If COMPATIBLE is set to 10.2.0 or higher, the final phase of redefinition automatically sets this column unused. You can then use the ALTER TABLE … DROP UNUSED COLUMNS statement to drop it.
You cannot use this method on index-organized tables.
Note:
* When you rebuild an index, you use an existing index as the data source. Creating an index in this manner enables you to change storage characteristics or move to a new tablespace. Rebuilding an index based on an existing data source removes intra-block fragmentation.
Compared to dropping the index and using the CREATE INDEX statement, re-creating an existing index offers better performance.
Incorrect:
Not E: Edition-based redefinition enables you to upgrade the database component of an application while it is in use, thereby minimizing or eliminating down time.
D
D
D – true.
D
D" . 24194) ((marker) . -1849) 26043 nil ("
" . -23529) ((marker . 15876) . -1) nil ("Explanation:
E: By default, flashback archiving is disabled for any table. You can enable flashback archiving for a table if you have the FLASHBACK ARCHIVE object privilege on the Flashback Data Archive that you want to use for that table.
D: Creating a Flashback Data Archive
/ Create a Flashback Data Archive with the CREATE FLASHBACK ARCHIVE statement, specifying the following:
Name of the Flashback Data Archive
Name of the first tablespace of the Flashback Data Archive
(Optional) Maximum amount of space that the Flashback Data Archive can use in the first tablespace
/ Create a Flashback Data Archive named fla2 that uses tablespace tbs2, whose data will be retained for two years:
CREATE FLASHBACK ARCHIVE fla2 TABLESPACE tbs2 RETENTION 2 YEAR;
D&E
D E
DE" . 23530) ((marker) . -764) 24294 nil ("Explanation:
About Altering the Default Full Data Redaction Value
You can alter the default displayed values for full Data Redaction polices. By default, 0 is the redacted value when Oracle Database performs full redaction (DBMS_REDACT.FULL) on a column of the NUMBER data type. If you want to change it to another value (for example, 7), then you can run the DBMS_REDACT.UPDATE_FULL_REDACTION_VALUES procedure to modify this value. The modification applies to all of the Data Redaction policies in the current database instance. After you modify a value, you must restart the database for it to take effect.
Note:
* The DBMS_REDACT package provides an interface to Oracle Data Redaction, which enables
you to mask (redact) data that is returned from queries issued by low-privileged users or an
application.
* UPDATE_FULL_REDACTION_VALUES Procedure
This procedure modifies the default displayed values for a Data Redaction policy for full redaction.
* After you create the Data Redaction policy, it is automatically enabled and ready to redact data.
* Oracle Data Redaction enables you to mask (redact) data that is returned from queries issued by low-privileged users or applications. You can redact column data by using one of the following methods:
/ Full redaction.
/ Partial redaction.
/ Regular expressions.
/ Random redaction.
/ No redaction.
Oracle Database Advanced Security Guide 12c, About Altering the Default Full Data Redaction Value
E
By default, 0 is the redacted value when Oracle Database performs full redaction (DBMS_REDACT.FULL) on a column of the NUMBER data type. If you want to change it to another value (for example, -1), then you can run the DBMS_REDACT.UPDATE_FULL_REDACTION_VALUES procedure to modify this value. The modification applies to all of the Data Redaction policies in the current database instance. After you modify a value, you must restart the database for it to take effect. You can find the current values by querying the REDACTION_VALUES_FOR_TYPE_FULL data dictionary view
E
D
reference
https://docs.oracle.com/cloud/latest/db121/ASOAG/redaction_config.htm#CACJHJFJ
Data redaction does not cover 1z0-062 exam topics.
https://education.oracle.com/pls/web_prod-plq-dad/db_pages.getpage?page_id=5001&get_params=p_exam_id:1Z0-062
E" . 22965) ((marker) . -2273) 25238 nil ("
" . -22393) ((marker . 15876) . -1) nil ("Explanation:
Note:
* SQL*Loader is invoked when you specify the sqlldr command and, optionally, parameters that establish session characteristics.
New enhancement on 12c called ‘express mode loading’
When specify only ‘table’ parameter, can go without controlfile
http://www.oracle.com/technetwork/database/enterprise-edition/learnmore/sqlldr-express-mode-wp-1991038.pdf
A&C
this question is not right. only A is true. Does not make any sense why hr would have to create a directory in an express sqlldr
I agree with Jav. Only A although they ask for ‘two’ which is in my opinion wrong.
A & C. Note that the external tables option uses directory objects in the database to indicate where all datafiles are stored and to indicate where output files, such as bad files and discard files, are created. You must have READ access to the directory objects containing the datafiles, and you must have WRITE access to the directory objects where the output files are created. If there are no existing directory objects for the location of a datafile or output file, SQL*Loader will generate the SQL statement to create one. Therefore, when the EXECUTE option is specified, you must have the CREATE ANY DIRECTORY privilege
A C
A,C
If no data file is specified, then SQL lOADER looks for a file named table-name.dat in the current directory.
External tables is the load method. For some errors, SQL*Loader express mode automatically switches from the default external tables load method to direct path load. An example of when this might occur would be if a privilege violation caused the CREATE DIRECTORY SQL command to fail
AC" . 22394) ((marker) . -1618) 24012 nil ("
" . -21828) ((marker . 15876) . -1) nil ("Explanation:
If you run multiple AUDIT statements on the same unified audit policy but specify different EXCEPT users, then Oracle Database uses the last exception user list, not any of the users from the preceding lists. This means the effect of the earlier AUDIT POLICY … EXCEPT statements are overridden by the latest AUDIT POLICY … EXCEPT statement.
Note:
* The ORA_DATABASE_PARAMETER policy audits commonly used Oracle Database parameter
settings. By default, this policy is not enabled.
* You can use the keyword ALL to audit all actions. The following example shows how to audit all actions on the HR.EMPLOYEES table, except actions by user pmulligan.
Example Auditing All Actions on a Table
CREATE AUDIT POLICY all_actions_on_hr_emp_pol
ACTIONS ALL ON HR.EMPLOYEES;
AUDIT POLICY all_actions_on_hr_emp_pol EXCEPT pmulligan;
Oracle Database Security Guide 12c, About Enabling Unified Audit Policies
B. All users except SCOTT
B
B
reference
https://docs.oracle.com/database/121/DBSEG/audit_config.htm#CHDHCEEG
B" . 21829) ((marker) . -1015) 22844 nil ("
" . -21348) ((marker . 15876) . -1) nil ("Explanation:
AB: You can make individual table columns invisible. Any generic access of a table does not show the invisible columns in the table. For example, the following operations do not display invisible columns in the output:
* SELECT * FROM statements in SQL
* DESCRIBE commands in SQL*Plus
* %ROWTYPE attribute declarations in PL/SQL
* Describes in Oracle Call Interface (OCI)
Incorrect:
Not D: You can make invisible columns visible.
You can make a column invisible during table creation or when you add a column to a table, and you can later alter the table to make the same column visible.
Understand Invisible Columns
A,B&E
A B E
Reference
http://www.oracle.com/technetwork/articles/database/invisible-columns-odb12c-2331522.html
can any1 explain why “A primary key constraint can be added on the invisible column” but not
“Referential integrity constraint cannot be set on the invisible column.”??
ok, i`ve checked it, it`s correct
ABE" . 21349) ((marker) . -948) 22297 nil (20670 . 20671) nil ("
" . -20670) ((marker . 5488) . -1) ((marker . 15876) . -1) nil ("SGA_TARGET = 512M
DB_8K_CACHE_SIZE = 128M
In this example, increasing DB_8K_CACHE_SIZE by 16 M to 144M means that the 16M is taken away from the automatically sized components. Likewise, reducing DB_8K_CACHE_SIZE by 16M to 112M means that the 16M is given to the automatically sized components.
i think B
B. Here is my test:
SQL> show parameter sga
NAME TYPE VALUE
———————————— ———– ——————————
lock_sga boolean FALSE
pre_page_sga boolean TRUE
sga_max_size big integer 1G
sga_target big integer 700M
unified_audit_sga_queue_size integer 1048576
SQL> show parameter log_buffer
NAME TYPE VALUE
———————————— ———– ——————————
log_buffer big integer 200M
SQL> show parameter db_16k
NAME TYPE VALUE
———————————— ———– ——————————
db_16k_cache_size big integer 124M
SQL> alter system set db_16k_cache_size=140m;
System altered.
B
B
It should be A. Just tested it.
8K is the default block size and it can’t be changed dynamically.
I tried to alter 8k cache size then get the ORA-00380
However, other cache size with different block size can be changed.
A
SQL> ALTER SYSTEM SET DB_8K_CACHE_SIZE=140M;
ALTER SYSTEM SET DB_8K_CACHE_SIZE=140M
*
ERROR at line 1:
ORA-02097: parameter cannot be modified because specified value is invalid
ORA-00380: cannot specify db_8k_cache_size since 8K is the standard block size
Yes is true assuming that db_block_size is equal to 8K.
b
a sory..
A is correct.
" . 20671) ((marker) . -1381) 22052 nil ("
" . -19264) ((marker . 15876) . -1) nil ("Explanation:
In this case we have run the impdp without performing any conversion if endian
format is different then we have to first perform conversion.
A,B&D
it’s AB and E.
It mentions same platform, different platforms with same endian format do not require this conversion.
Besides, E is correct. If the path for the datafiles where different in target environment, the remap_datafile clause would have to be used in the impdp since the metadata of the source specifies the required datafiles with it’s path for the exported tablespaces.
A,B&D
A B D
Why B is correct?
I think ADE
Look into documentation: ” In the source database, make the user-defined tablespaces in the database read-only”
ABE
ABD
ABD, but E is true too, not ?
" . 19265) ((marker) . -734) 19999 nil ("
" . -18378) ((marker . 15876) . -1) nil ("Explanation:
* SET_TABLE_PREFS Procedure
This procedure is used to set the statistics preferences of the specified table in the specified schema.
* Example:
Using Pending Statistics
Assume many modifications have been made to the employees table since the last time statistics were gathered. To ensure that the cost-based optimizer is still picking the best plan, statistics should be gathered once again; however, the user is concerned that new statistics will cause the optimizer to choose bad plans when the current ones are acceptable. The user can do the following:
EXEC DBMS_STATS.SET_TABLE_PREFS(‘hr’, ’employees’, ‘PUBLISH’, ‘false’);
By setting the employees tables publish preference to FALSE, any statistics gather from now on will not be automatically published. The newly gathered statistics will be marked as pending.
C,D,E
Why Max?
C D E
CDE" . 18379) ((marker) . -856) 19235 nil ("Explanation:
* Automatic segment space management (ASSM) is a simpler and more efficient way of managing space within a segment. It completely eliminates any need to specify and tune the pctused,freelists, and freelist groups storage parameters for schema objects created in the tablespace. If any of these attributes are specified, they are ignored.
* Oracle introduced Automatic Segment Storage Management (ASSM) as a replacement for traditional freelists management which used one-way linked-lists to manage free blocks with tables and indexes. ASSM is commonly called “bitmap freelists” because that is how Oracle implement the internal data structures for free block management.
Note:
* Buffer busy waits are most commonly associated with segment header contention onside the data buffer pool (db_cache_size, etc.).
* The most common remedies for high buffer busy waits include database writer (DBWR) contention tuning, adding freelists (or ASSM), and adding missing indexes.
D
D
D
D
But you can’t change a tablespace from segment space management manual to automatic, therefor you must create a new tablespace and will have downtime and this isn’t an immediate solution.
" . 17691) ((marker) . -1177) 18868 nil ("Explanation:
* Evolving SQL Plan Baselines

*
2. Create the evolve task by using the DBMS_SPM.CREATE_EVOLVE_TASK function.This function creates an advisor task to prepare the plan evolution of one or more plans for a specified SQL statement. The input parameters can be a SQL handle, plan name or a list of plan names, time limit, task name, and description.
1. Set the evolve task parameters.
SET_EVOLVE_TASK_PARAMETER
This function updates the value of an evolve task parameter. In this release, the only valid parameter is TIME_LIMIT.
4. Execute the evolve task by using the DBMS_SPM.EXECUTE_EVOLVE_TASK function.
This function executes an evolution task. The input parameters can be the task name, execution name, and execution description. If not specified, the advisor generates the name, which is returned by the function.
3: IMPLEMENT_EVOLVE_TASK
This function implements all recommendations for an evolve task. Essentially, this function is equivalent to using ACCEPT_SQL_PLAN_BASELINE for all recommended plans. Input parameters include task name, plan name, owner name, and execution name.
5. Report the task outcome by using the DBMS_SPM_EVOLVE_TASK function. This function displays the results of an evolve task as a CLOB. Input parameters include the task name and section of the report to include.
Oracle Database SQL Tuning Guide 12c, Managing SQL Plan Baselines
B
Yes B
https://docs.oracle.com/database/121/TGSQL/tgsql_spm.htm#GUID-15A23B74-8B43-49EA-83CE-14F2C209C9A9__CDEGEHCC
B
B" . 17089) ((marker) . -1499) 18588 nil ("* SQL Access Advisor is primarily responsible for making schema modification recommendations, such as adding or dropping indexes and materialized views. SQL Tuning Advisor makes other types of recommendations, such as creating SQL profiles and restructuring SQL statements.
* The query optimizer can also help you tune SQL statements. By using SQL Tuning Advisor and SQL Access Advisor, you can invoke the query optimizer in advisory mode to examine a SQL statement or set of statements and determine how to improve their efficiency. SQL Tuning Advisor and SQL Access Advisor can make various recommendations, such as creating SQL profiles, restructuring SQL statements, creating additional indexes or materialized views, and refreshing optimizer statistics.
Note:
* Decision support system (DSS) workload
* The library cache is a shared pool memory structure that stores executable SQL and PL/SQL code. This cache contains the shared SQL and PL/SQL areas and control structures such as locks and library cache handles.
Tuning SQL Statements
Why D is incorrect?
Sorry, D is correct.
D is correct.
From the student guide, it mentioned “Even though you can submit multiple statements to be analyzed in a single task, each statement is analyzed independently. To obtain tuning recommendations that consider overall performance of a set of SQL, use the SQL Access Advisor.”
For ADDM, “By building on the data captured in the AWR, the ADDM enables the Oracle Database server to diagnose its own performance and determine how identified problems can be resolved.”
The SQL Performance Analyzer can be used to predict and prevent potential performance problems for any database environment change that affects the structure of the SQL execution plans.
So the best answer should be D.
D" . 16378) ((marker) . -1777) 18155 nil (15462 . 15463) nil ("
" . -15462) nil ("
" . -15462) ((marker . 15876) . -1) nil ("
" . -15463) ((marker . 15876) . -1) nil ("BC
This on is BC
https://docs.oracle.com/database/121/DBSEG/authorization.htm#DBSEG99937
B C
B and C may be correct but D is as well. Unlimited tablespace is a privilege in the resource role. The number of correct answers for this question is off….
For D, please note that from 12c onwards, “Resource” role will not provide “unlimited tablespace” privilege and no longer available too. As we already know resource role is deprecated from 11g onwards and will not be available in future releases.
B and C are correct, in Oracle 12C “RESOURCE role will no longer grant the UNLIMITED TABLESPACE system privilege by default.”
http://docs.oracle.com/database/121/DBSEG/release_changes.htm#BABEBGDI
BC
B-C
BC" . 15464) ((marker) . -702) 16166 nil ("
" . -15046) ((marker . 15876) . -1) nil ("A is correct. Even after a restart the conditions triggering the alert still exist.
It is OK that the following threshold alerts disappeared:
“Current Logons Count”
“Database Time Spent for event class “Application”
db_recovery_file_dest_size ….. remaining bytes available.
The question is why?
I think D is more appropriate…….
No…..A is correct
It is A
Entries from DBA_AUTSTANDING_ALERTS are cleared when the alert condition is cleared. They are then moved to DBA_alert_history
A
I think A is correct
DBA_OUTSTANDING_ALERTS: The DBA_OUTSTANDING_ALERTS means describes the outstanding alerts in the database and contains current database alerts.
DBA_ALERT_HISTORY: The DBA_ALERT_HISTORY means lists a history of alerts that have been cleared and provides a history of nonthreshold alerts.
I think the answer is A.
Even after restart, if the condition which triggered the alert still existed, the alert wouldn’t disappear.
And the table d0A_alert_history should be DBA_ALERT_HISTORY
A
A" . 15047) ((marker) . -986) 16033 nil ("1 row created.
SQL> insert into x values (4);
1 row created.
SQL> insert into x values (2);
1 row created.
SQL> select * from x order by y;
Y
———-
1
2
3
4
5
Correct as winner2001 points out is A and D
Great looking website. Think you did a bunch of your ownyour very own html coding
csgo http://nhlcoinstory.inube.com/blog/4989728/csgo-skins-instead-obtain-a-mobile-console/
AD
that is the finish of this article. Here youll discover some sites that we consider you will value, just click the links over
below you will uncover the link to some web-sites that we consider you should visit
just beneath, are many absolutely not connected web pages to ours, on the other hand, they’re surely really worth going over
A and D
SQL> conn sidney/out_standing1
Connected.
SQL> create table dummy (a varchar2(10));
create table dummy (a varchar2(10))
*
ERROR at line 1:
ORA-01031: insufficient privileges" . 14005) ((marker) . -894) 14899 nil ("
" . -12010) ((marker . 15876) . -1) nil ("BC
It’s B and C
Check
https://docs.oracle.com/database/121/CNCPT/logical.htm#CNCPT1061
B C
BC
BC" . 12011) ((marker) . -96) 12107 nil ("And the correct answer is C:
The size of the PGA cannot grow automatically beyond 500 MB
The correct option will be B.
When MEMORY_TARGET is set to a NON-ZERO value and if SGA_TARGET or PGA_TARGET is set to 0 or any positive number, then that number is taken as the minimum value. In that case it can definitely grow beyond 500 M.
B
B
—————————————————-
http://www.dba-oracle.com/t_amm_automatic_memory.htm
memory_target (starting in 11g): If memory_target is set, then AMM is enabled: If memory_target is set to non zero value and :
* sga_target and pga_aggregate_target are set to non-zero values, then these values will be considered minimum values.
* pga_aggregate_target is set and sga_target is not set. Both parameters will be auto-tuned. The sga_target will be initialized to a value of (memory_target-pga_aggregate_target).
I think it’s B. For reference 12c : http://docs.oracle.com/database/121/ADMIN/memory.htm#ADMIN11199
B
B is correct
If memory_target is set, then AMM is enabled.
If memory_target is set to non zero value and pga_aggregate_target is set and sga_target is not set. Both parameters will be auto-tuned. The sga_target will be initialized to a value of (memory_target-pga_aggregate_target).
B
B
PGA_AGGREGATE_TARGET is a minimum value, NOT a maximum one.
If the memory_target is non zero. PGA + SGA = MEMORY_TARGET" . 11572) ((marker) . -1341) 12913 nil ("As the doc:
The next startup of the database will not require any instance recovery procedures.
Not b: uncommited transactions are rolled back but not during startup.
I mean “The next startup of the database will not require any instance recovery procedures.” for immediate option
I totally agree with Liz and Winner2001. Only E is correct.
I agree only E is correct.
B wrong.
Uncommitted transactions are rolled back during the shutdown immediate and not during start up
E is correct
E is the correct answer :
Docummentation: http://docs.oracle.com/cd/A87860_01/doc/server.817/a76956/start.htm
extract from link:
Shutting Down with the IMMEDIATE Option
Use immediate database shutdown only in the following situations:
A power shutdown is going to occur soon.
The database or one of its applications is functioning irregularly.
Immediate database shutdown proceeds with the following conditions:
Any uncommitted transactions are rolled back. (If long uncommitted transactions exist, this method of shutdown might not complete quickly, despite its name.)
Oracle does not wait for users currently connected to the database to disconnect; Oracle implicitly rolls back active transactions and disconnects all connected users.
The next startup of the database will not require any instance recovery procedures.
E
E
E
roll back si during shutdown" . 10810) ((marker) . -1341) 12151 nil ("C
C
Once a client is connected to the database (ie the server-side process is forked or is using a shared server process), the listener isn’t required any further. You could even shutdown the listener (preventing new connections) without affecting existing connections.
it should be C
Maybe D
Configuring Dynamic Service Registration
Service registration allows processes, such as an Oracle database, to identify their available services to the listener, which then acts as a port mapper for those services. The listener uses the dynamic service information about the database and instance received through service registration.
Dynamic service registration is configured in the database initialization file. It does not require any configuration in the listener.ora file. However, listener configuration must be set to listen on the ports named in the database initialization file, and must not have parameters set that prevent automatic registration, such as COST parameters.
This section contains the following configuration topics related to service registration:
Why B? I think C is correct
C is correct as RELOAD only read the listner.ora file and won’t affect existing connections
In addition, the database services, instances, service handlers, and listening endpoints that were dynamically registered with the listener will be unregistered and subsequently registered again.
I think B is correct but the Reload not take to much time so look like no affected and continue to function normally
C
C, listener only delivery the session to database after that isn’t listener’s responsability
C
Even STOP would NOT affect any established sessions." . 10058) ((marker) . -1650) 11708 nil ("
" . -9464) ((marker . 15876) . -1) nil ("Refer – http://docs.oracle.com/cd/E18283_01/server.112/e17120/schema003.htm#CBBBIADA, Shrinking Database Segments Online
The correct answer will be enable row movement.
Segment shrink requires that rows be moved to new locations. Therefore, you must first enable row movement in the object you want to shrink and disable any rowid-based triggers defined on the object. You enable row movement in a table with the ALTER TABLE … ENABLE ROW MOVEMENT command.
Segment shrink is an online, in-place operation. DML operations and queries can be issued during the data movement phase of segment shrink. Concurrent DML operations are blocked for a short time at the end of the shrink operation, when the space is deallocated. Indexes are maintained during the shrink operation and remain usable after the operation is complete. Segment shrink does not require extra disk space to be allocated.
Reference for 12c : http://docs.oracle.com/database/121/ADMIN/schema.htm#ADMIN10161
Correct should be: A
A and A and only A
A
A is correct because:
– DML operations and queries can be issued during the data movement phase of segment shrink
– Segment shrink does not require extra disk space to be allocated
– Segment shrink requires that rows be moved to new locations. Therefore, you must first enable row movement in the object you want to shrink and disable any rowid-based triggers defined on the object. You enable row movement in a table with the ALTER TABLE … ENABLE ROW MOVEMENT command.
http://docs.oracle.com/database/121/ADMIN/schema.htm#ADMIN10161
A
A" . 9465) ((marker) . -1549) 11014 nil ("Refer – http://docs.oracle.com/cd/E18283_01/server.112/e17120/schema003.htm#CBBBIADA, Shrinking Database Segments Online
The correct answer will be enable row movement.
Sorry this comment is for Q. 150
C
Little tricky question, DBUA runs Pre-Upgrade tool as one of its steps. However Oracle recommends to run the tool before starting DBUA to run the tool ahead of time in order to analyze the database and take actions that can decrease downtime for upgrading.
BTW expl. link leads to 11g not 12c, there is the correct one:
http://docs.oracle.com/database/121/UPGRD/upgrade.htm#i1011482
C is correct one.
C
C
DVLA Number Plates
http://www.zkRCZC3urT.com/zkRCZC3urT
C" . 8631) ((marker) . -666) 9297 nil ("C
B
All dirty buffers are write to the datafiles only during FULL CHECKPOINT (When you for example issue: shutdown immediate).
I think it’s C because LGWR is called only if some redo has not been already processed, so in theory it’s possible that LGWR isn’t called at all.
Sayed’s advice is nearly every time correct. This is a rare exception. B seems to be correct: ‘The database writes to disk all buffers modified by redo before a specific target.’
DBWn is and has to be lazy. Only in full checkpoint he writes all dirty buffer to datafiles.
Additionally the question is ‘a file checkpoint’ which is a clear hint that ‘all dirty buffers’ can NOT be the correct answer.
C is correct.
B says: “All buffers for a checkpointed file that were modified before a specific SCN”
But it should be like “All buffers for a checkpointed file that were modified AFTER a specific SCN”
Buffers BEFORE a specific SCN should have been already written to disk then SCN have been given.
C
B is correct.
Checkpoint SCN
Every data file has a data file checkpoint SCN, which you can view in V$DATAFILE.CHECKPOINT_CHANGE#. All changes with an SCN lower than this SCN are guaranteed to be in the file. When a level 0 incremental backup is restored, the restored data file contains the checkpoint SCN that it had when the level 0 was created. When a level 1 incremental backup is applied to a file, the checkpoint SCN of the file is advanced to the checkpoint SCN that the file had when the incremental level 1 backup was created.
-> https://docs.oracle.com/database/121/BRADV/rcmcncpt.htm#BRADV90078
I think B is correct
Every data file has a data file checkpoint SCN.
These checkpoints occur in a variety of situations, including making a tablespace read-only or taking it offline normal, shrinking a data file, or executing ALTER TABLESPACE BEGIN BACKUP.
when these checkpoints occur, the database writes to disk all buffers modified by redo before a specific target
By the book of certification OCA Administrator Certified Assosiate Study Guide
” A checkpoint is when the DBWn process writes all the dirty buffers to the data files. When a checkpoint occurs, Oracle must update the control file and each data file header to record the checkpoint. This update is done by the checkpoint process (CKPT); the DBWn process writes the actual data blocks to the data files.”
So, I think that the answer is correct.
Answer: C
B
The Correct Answer this C.
Checkpoint: Updates the data file headers following a checkpoint
event.
Thomas. “OCA: Oracle®Database 12c Administrator Certified Associate”, pp. 467
C" . 8229) ((marker) . -2579) 10808 nil ("CE
C E
why C and E are correct?
C: Cumulative amount of time that sessions waited for CPU because of resource management. This does not include waits due to latch or enqueue contention, I/O waits, and so on. When CPU resources are not being actively managed, this value is set to zero.
E: Number of sessions waiting in the queue – the numbers are next to each other without any space, but u can clearly see, that queue_lenght is more than 0. That means, session can be established, but cannot be active at the moment (active session is defined as session that is running a query or has uncommited transaction)
btw. does any1 has any latest dumps of questions from iz0-062? I would really appreciate.
By the way, the chart (or exhibit) is awful… I can’t see there anything!
CE
CE" . 7753) ((marker) . -778) 8531 nil ("This questions said: “Which three factors” and only have two correct answers, i think you forgot one.
Third option will be D
A, C, E
http://docs.oracle.com/cd/B10500_01/server.920/a96533/optimops.htm
Sorry it is A, C, D!
ACD
A,C,D
a, c , d
A,C,D
A C D
why not A B D ?
those statistics are being used aswell by the optimizer
I think B-C-D
http://docs.oracle.com/database/121/TGSQL/tgsql_optcncpt.htm#TGSQL193
You are wrong. “Operating system statistics” are not the same like “Hardware statistics”.
The correct answers are: A,C,D
total confusion for me about the correct answer; this question is posed in gratis exam and the correct answer was A,B,D. Now you say here that the correct answer is A,C,D. Finally what is the correct answer?
The correct answers are: A,C,D
ACD
ACD
A, D and E
Techniques for Influencing the Optimizer such as
1- dbms_stas
2- sql profile,
3- hints
4- sql plan manager (baselines)
5- init parameter
https://docs.oracle.com/database/121/TGSQL/tgsql_influence.htm#TGSQL246" . 6649) ((marker . 5488) . -133) ((marker) . -995) 7644 nil ("
" . -6396) ((marker . 15876) . -1) nil ("A, B
“Data life”, does it mean to “data file”?
A,B
D is nonsense
Hugo I think this is the perfect description. D is nonsense!
A,B
i think A-B is correct
ORA-01653: unable to extend table string. string by string in tablespace string
Cause: Failed to allocate an extent of the required number of blocks for a table segment in the tablespace indicated.
Action: Use ALTER TABLESPACE ADD DATAFILE statement to add one or more files to the tablespace indicated.
Add a DATAFILE
Resize DATAFILE
Enable AUTOEXTEND
AB
AB
I believe AD is correct since this table space could be a bigfile tablespace, and you have more than one data file in a bigfile tablespace.
This is not sense, a bigfile tablespace only have a datafile." . 6397) ((marker) . -713) 7110 nil ("ABE
A,B,E – that’s right.
ABE
ABE" . 5557) ((marker) . -33) 5590 nil ("
" . -5204) ((marker . 15876) . -1) nil ("http://docs.oracle.com/cd/B28359_01/server.111/b28310/tables013.htm#ADMIN01507
Correct Answer will be D and E.
No DML is not allowed on External Table
No Index can be created on External Table
D,E
http://docs.oracle.com/cd/B28359_01/server.111/b28310/tables013.htm#ADMIN01507
You can, for example, select, join, or sort external table data. You can also create views and synonyms for external tables. However, no DML operations (UPDATE, INSERT, or DELETE) are possible, and no indexes can be created, on external tables.
D E
I think D – E are correct
D-E correct, I think
http://docs.oracle.com/database/121/ADMIN/tables.htm#i1007424
DE
Very handful of web sites that occur to be in depth below, from our point of view are undoubtedly effectively really worth checking out.
DE" . 5205) ((marker) . -776) 5981 nil ("CD
They ask for one method. So I think just D.
http://docs.oracle.com/cd/B28359_01/server.111/b28310/manproc001.htm#ADMIN11167
“To request a dedicated server connection when Oracle Database is configured for shared server, users must connect using a net service name that is configured to use a dedicated server. Specifically, the net service name value should include the SERVER=DEDICATED clause in the connect descriptor.”
So I think D is ans
D
D
Same as Liz said, also reference to 12c doc
http://docs.oracle.com/database/121/ADMIN/manproc.htm#ADMIN11167
D is the only answer which is correct. Create service procedure dont have any attribute for dedicated and share.
Also this type of connection is maintained at connection level.
D
D
I think B and D. Because with easy connection you can specify server type: dedicaded or shared." . 4987) ((marker) . -834) 5821 nil ("LGWR writes:
•A commit record when a user process commits a transaction
•Redo log buffers
•Every three seconds
•When the redo log buffer is one-third full
•When a DBWn process writes modified buffers to disk, if necessary
D as pointed out by Sayed
D
D IS CORRECT.
C is wrong because LGWR writes before the Database Writer process writes dirty buffers to disk.
infact if DBW discovers that some redo records have not been written, it signals LGWR to write the records to disk, and waits for LGWR to complete before writing the data buffers to disk.
Why is it B wrong, tho? D is perfectly fine, but why not B?
LGWR writes concurrently to group 1 (members A_LOG1 and B_LOG1), then writes concurrently to group 2 (members A_LOG2 and B_LOG2), then writes to group 1, and so on. LGWR never writes concurrently to members of different groups.
from
https://docs.oracle.com/database/121/CNCPT/physical.htm#CNCPT11305
Answer is D, there is no concept of multiplexd Redo log groups, only have an option for multiplexing of redo log members. The option B is wrong because, log writer won’t write to multiplexed redo groups(multiple redo log groups) concurrently and writes to multiplexed redo memebrs in the same redo log group concurrently.
D" . 4290) ((marker) . -1231) 5521 nil ("B&C
B and C
A single extent can never span data files.
From: https://docs.oracle.com/database/121/CNCPT/logical.htm#CNCPT1095
B C
BC
BC
BC" . 3898) ((marker) . -138) 4036 nil ("D,E
According to the link, “A data block is the minimum unit of database I/O.”
So, ans is DE
Isn’t A also correct? For this kind of question is there 3 correct answer so if you choose any two out from this you also get the question right?
A is not correct. It should be logically contiguous. However, does anyone know B is correct or not?
D, E
B is wrong
https://docs.oracle.com/database/121/CNCPT/logical.htm#i10251
Answers : D and E
I tried to provide explanation below I hope it will be helpfull
https://docs.oracle.com/cd/E11882_01/server.112/e40540/logical.htm#CNCPT3000
A : An extent is a set of logically contiguous data blocks allocated for storing a specific type of information
B: a segment can include extents from multiple data files, as shown in Figure 12-2
C:?
D:https://docs.oracle.com/cd/B28359_01/server.111/b28310/tspaces003.htm
Specifying Nonstandard Block Sizes for Tablespaces
E:This is know by everyone :) you can see it from the link
https://docs.oracle.com/cd/E11882_01/server.112/e40540/logical.htm#CNCPT3000
Figure 12-1 Logical and Physical Storage
D, E
DE
D??
CREATE TABLESPACE TEST LOGGING DATAFILE SIZE 100M AUTOEXTEND ON NEXT 10M MAXSIZE UNLIMITED blocksize 16K
*
ERROR at line 1:
ORA-29339: tablespace block size 16384 does not match configured block sizes" . 3562) ((marker) . -1287) 4849 nil ("C
 why is C and not B correct? It’s obvious that A and D can not fullfill the requieremets.
Why not B:
> The number of concurrent user connections will be high.
“dedicated server mode” as stated in B is not the best option for that requirement.
I have checked C and on my fail feedback objectives for which i anwsered incorrectly i have: Manage database design templates by using DBCA
Answer C: a General Purpose database template, with the shared server mode option and Automatic Memory Management (AMM) enabled
Applications will connect to the database via a middle tier: This More over Middleware component like WebLogic , WebSphere or any other middleware tool – Mostly for Transactional Application ( OLTP)
The number of concurrent user connections will be high : OLTP ( Default/General Purpose DB is for high transnational application / for high #connections/users (Login from Middleware – Or might be suing connection pooling in Middleware component)
The database will have mixed workload, with the execution of complex BI queries scheduled at
night. : There are some adhoc or daily to door reports runs in OLTP, also might be some kind of data transfer from OLTP to DW (reporting)
C
Sorry Antilope……I did not get back to this site for a long….however I believe you have got the answer from others above
C
C
C" . 3154) ((marker) . -1316) 4470 nil ("C
A job that is running will not close when the window it is running in closes unless the attribute stop_on_window_close was set to TRUE when the job was created. However, the resources allocated to the job may change because the resource plan may change.
I think that D is correct
D is correct.
C is correct one. The GATHER_STATS_JOB continues until it finishes, even if it exceeds the allocated time for the maintenance window. The default behavior of the maintenance window can be changed
So finnaly i think D is right. The stop_on_window_close attribute controls whether the GATHER_STATS_JOB continues when the maintenance window closes. The default setting for the stop_on_window_close attribute is TRUE, causing Scheduler to terminate GATHER_STATS_JOB when the maintenance window closes. The remaining objects are then processed in the next maintenance window.
Correct is C
By default, stop_on_window_close is set to FALSE. Therefore, if you do not set this attribute, the job continues after the window closes.
From : https://docs.oracle.com/database/121/ARPLS/d_sched.htm#ARPLS72362
Above considerations and option C is correct when stats collection is scheduled through DBMS_SCHEDULER.
STOP_ON_WINDOW attribute is set at job level in DBA_SCHEDULER_JOBS.
But from 11g onwards stats collection is being taken cared by AUTOTASK admin, where there is no such clause. So option D in correct if we consider 11g and 12c.
D
I think D is correct
https://docs.oracle.com/cd/B19306_01/server.102/b14211/stats.htm
This job is created automatically at database creation time and is managed by the Scheduler. The Scheduler runs this job when the maintenance window is opened. By default, the maintenance window opens every night from 10 P.M. to 6 A.M. and all day on weekends.
The stop_on_window_close attribute controls whether the GATHER_STATS_JOB continues when the maintenance window closes. The default setting for the stop_on_window_close attribute is TRUE, causing Scheduler to terminate GATHER_STATS_JOB when the maintenance window closes. The remaining objects are then processed in the next maintenance window.
The link shared is of 10g, in 11g & 12C the default value of the parameter stop_on_window_close is false and hence C should be correct considering 1z0-062.
But if you look into source code of jobs, you will see, that job responsible for statistics collecting is running with parameter stop_on_window_close=TRUE.
In 12c, ANSWER is C because the default of parameter STOP_ON_WINDOW_CLOSE is FALSE.
“By default, stop_on_window_close is set to FALSE. Therefore, if you do not set this attribute, the job continues after the window closes.”
https://docs.oracle.com/database/121/ARPLS/d_sched.htm#ARPLS72362
C is correct. Please see below from Oracle web site:
stop_on_window_close
This attribute only applies if the schedule of a job is a window or a window group.
Setting this attribute to TRUE implies that the job should stop once the associated window is closed.
The job is stopped using the stop_job procedure with force set to FALSE.
By default, stop_on_window_close is set to FALSE.
Therefore, if you do not set this attribute, the job continues after the window closes.
Note that, although the job is allowed to continue, its resource allocation will probably change because closing a window generally also implies a change in resource plans.
D
If the job belong a some window or windows group, by default the job continue , however the resource plan is changed.
C is correct!
C
stop_on_window_close
This attribute only applies if the schedule of a job is a window or a window group. Setting this attribute to TRUE implies that the job should stop once the associated window is closed. The job is stopped using the stop_job procedure with force set to FALSE.
By default, stop_on_window_close is set to FALSE. Therefore, if you do not set this attribute, the job continues after the window closes.
Note that, although the job is allowed to continue, its resource allocation will probably change because closing a window generally also implies a change in resource plans.
https://docs.oracle.com/database/121/ARPLS/d_sched.htm#ARPLS72362" . 2435) ((marker . 5488) . -679) ((marker) . -4154) 6589 nil ("D is the one.
Answer=C
Since all users in orcl database has to access the DB link, hence public DB has to be created Database links are either private or public. If they are private, then only the user who created the link has access; if they are public, then all database users have access.
According to question it should be public which can be accessed by all users.
Since all users are connected as scott, so it should be a fixed user link.
Then I think C is more reasonable.
C is correct
I agree that B is wrong for two reasons:
1.) Liz Statement is correct an private db-link does NOT fullfill the requirements ‘scuh that all users’. => onnly C can be right.
2.) If you use current_user than “The current user must be a global user with a valid account on the remote database.” But there is no Information that this user is a global user. on the contrary: ‘as a user of the orcl database’. => B is for sure wrong and C must be right.
C
The Oracle docs note the syntax for creating an Oracle dblink as follows:
CREATE [ SHARED ] [ PUBLIC ] DATABASE LINK dblink
[ CONNECT TO
{ CURRENT_USER
| user IDENTIFIED BY password
[ dblink_authentication ]
}
| dblink_authentication
]
[ USING ‘connect_string’ ] ;
C is correct
C
The CONNECT TO clause specifies the username and password to connect to the remote database. This is known as a fixed user database link. The user_name and password portion may be omitted in order to use the same credentials that were used to connect to the local database to connect to the remote database. This type of dblink is called connected user database link. The database link privileges depend on the user connecting to the remote database.
then… maybe is A
C is the correct answer." . 1998) ((marker) . -1714) 3712 nil ("
" . -1380) ((marker . 15876) . -1) nil ("D" . -1381) ((marker . 15876) . -1) nil ("
D
the real question’s choices are:
choose two:
A)implement Resourse Manager and assign it a profile for the user
B)implement Resourse Manager and assign it a rle for the user
C)alter appropriate user attributes with an alter user command
D) use appropriate KERNEL parameters set in the profile assigned to the user
E) use appropriate PASSWORD parameters set in the profile assigned to the user
The answers to these questions are : A,C
I think
A and E
D for sure
https://docs.oracle.com/cd/B28359_01/server.111/b28286/statements_6010.htm
D" . 1382) ((marker) . -539) 1921 nil ("D
Also correct answer in 1st question is D
To guarantee the success of long-running queries or Oracle Flashback operations, you can enable retention guarantee. If retention guarantee is enabled, the specified minimum undo retention is guaranteed; the database never overwrites unexpired undo data even if it means that transactions fail due to lack of space in the undo tablespace. If retention guarantee is not enabled, the database can overwrite unexpired undo when space is low, thus lowering the undo retention for the system. This option is disabled by default." . 745) ((marker) . -566) 1311 nil ("g" . -5) nil (5 . 6) nil (1 . 265147) (t . -1)))
